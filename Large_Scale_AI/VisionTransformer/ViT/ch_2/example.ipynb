{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNPQlWRO/j2Jg4CcefvScS3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"S1u_onH8nlLd"},"outputs":[],"source":["# -*- coding: utf-8 -*-\n","2\n","\n","\n","\n","3\n","# ----------------------------\n","4\n","# 必要なライブラリをインポート\n","5\n","# ----------------------------\n","6\n","import torch\n","7\n","import torch.nn as nn\n","8\n","\n","\n","\n","9\n","\n","\n","\n","10\n","# ----------------------------\n","11\n","# 2-1 準備\n","12\n","# ----------------------------\n","13\n","print(\"=======2-1 準備=======\")\n","14\n","\n","\n","\n","15\n","class SimpleMlp(nn.Module):\n","16\n","   def __init__(self, vec_length:int=16, hidden_unit_1:int=8, hidden_unit_2:int=2):\n","17\n","       \"\"\"\n","18\n","       引数:\n","19\n","           vec_length: 入力ベクトルの長さ\n","20\n","           hidden_unit_1: 1つ目の線形層のニューロン数\n","21\n","           hidden_unit_2: 2つ目の線形層のニューロン数\n","22\n","       \"\"\"\n","23\n","       # 継承しているnn.Moduleの__init__()メソッドの呼び出し\n","24\n","       super(SimpleMlp, self).__init__()\n","25\n","       # 1つ目の線形層\n","26\n","       self.layer1 = nn.Linear(vec_length, hidden_unit_1)\n","27\n","       # 活性化関数のReLU\n","28\n","       self.relu = nn.ReLU()\n","29\n","       # 2つ目の線形層\n","30\n","       self.layer2 = nn.Linear(hidden_unit_1, hidden_unit_2)\n","31\n","\n","\n","\n","32\n","\n","\n","\n","33\n","   def forward(self, x: torch.Tensor) -> torch.Tensor:\n","34\n","       \"\"\"順伝搬は、線形層→ReLU→線形層の順番\n","35\n","       引数:\n","36\n","           x: 入力。(B, D_in)\n","37\n","               B: バッチサイズ、 D_in: ベクトルの長さ\n","38\n","       返り値:\n","39\n","           out: 出力。(B, D_out)\n","40\n","               B: バッチサイズ、 D_out: ベクトルの長さ\n","41\n","       \"\"\"\n","42\n","       # 1つ目の線形層\n","43\n","       out = self.layer1(x)\n","44\n","       # ReLU\n","45\n","       out = self.relu(out)\n","46\n","       # 2つ目の線形層\n","47\n","       out = self.layer2(out)\n","48\n","       return out\n","49\n","\n","\n","\n","50\n","vec_length = 16 # 入力ベクトルの長さ\n","51\n","hidden_unit_1 = 8 # 1つ目の線形層のニューロン数\n","52\n","hidden_unit_2 = 2 # 2つ目の線形層のニューロン数\n","53\n","\n","\n","\n","54\n","batch_size = 4 # バッチサイズ。入力ベクトルの数\n","55\n","\n","\n","\n","56\n","# 入力ベクトル。xの形状: (4, 16)\n","57\n","x = torch.randn(batch_size, vec_length)\n","58\n","# MLPを定義\n","59\n","net = SimpleMlp(vec_length, hidden_unit_1, hidden_unit_2)\n","60\n","# MLPで順伝搬\n","61\n","out = net(x)\n","62\n","# MLPの出力outの形状が(4, 2)であることを確認\n","63\n","print(out.shape)\n"]}]}