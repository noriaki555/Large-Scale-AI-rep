{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# 第8章 文埋め込み"],"metadata":{"id":"vA23hdhp5I6T"}},{"cell_type":"markdown","source":["# 第8章 文埋め込み"],"metadata":{"id":"ESintlMl9cr8"}},{"cell_type":"markdown","source":["## 8.4 最近傍探索ライブラリ `Faiss` を使った検索"],"metadata":{"id":"AbqWCDzU9iTN"}},{"cell_type":"markdown","source":["### 8.4.2 `Faiss`を利用した最近傍探索の実装"],"metadata":{"id":"1UaVdbG-sr79"}},{"cell_type":"markdown","source":["#### 準備"],"metadata":{"id":"1Kxu3NA5Ctq2"}},{"cell_type":"code","source":["!pip install datasets faiss-cpu scipy transformers[ja,torch]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mIAZKDU_Co6V","outputId":"c8072309-041d-43cd-8103-ecc4e64172ac"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting datasets\n","  Downloading datasets-2.13.1-py3-none-any.whl (486 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m486.2/486.2 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting faiss-cpu\n","  Downloading faiss_cpu-1.7.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m63.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.10.1)\n","Collecting transformers[ja,torch]\n","  Downloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m114.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.22.4)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n","Collecting dill<0.3.7,>=0.3.0 (from datasets)\n","  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.27.1)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.65.0)\n","Collecting xxhash (from datasets)\n","  Downloading xxhash-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting multiprocess (from datasets)\n","  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.4)\n","Collecting huggingface-hub<1.0.0,>=0.11.0 (from datasets)\n","  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[ja,torch]) (3.12.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[ja,torch]) (2022.10.31)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers[ja,torch])\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m50.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors>=0.3.1 (from transformers[ja,torch])\n","  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting fugashi>=1.0 (from transformers[ja,torch])\n","  Downloading fugashi-1.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (599 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m599.9/599.9 kB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting ipadic<2.0,>=1.0.0 (from transformers[ja,torch])\n","  Downloading ipadic-1.0.0.tar.gz (13.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m72.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting unidic-lite>=1.0.7 (from transformers[ja,torch])\n","  Downloading unidic-lite-1.0.8.tar.gz (47.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.4/47.4 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting unidic>=1.0.2 (from transformers[ja,torch])\n","  Downloading unidic-1.1.0.tar.gz (7.7 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting sudachipy>=0.6.6 (from transformers[ja,torch])\n","  Downloading SudachiPy-0.6.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m108.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting sudachidict-core>=20220729 (from transformers[ja,torch])\n","  Downloading SudachiDict-core-20230110.tar.gz (9.0 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting rhoknp<1.3.1,>=1.1.0 (from transformers[ja,torch])\n","  Downloading rhoknp-1.3.0-py3-none-any.whl (86 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch!=1.12.0,>=1.9 in /usr/local/lib/python3.10/dist-packages (from transformers[ja,torch]) (2.0.1+cu118)\n","Collecting accelerate>=0.20.2 (from transformers[ja,torch])\n","  Downloading accelerate-0.20.3-py3-none-any.whl (227 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.6/227.6 kB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.20.2->transformers[ja,torch]) (5.9.5)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.0.12)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.7.1)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (1.26.16)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.5.7)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.9->transformers[ja,torch]) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.9->transformers[ja,torch]) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.9->transformers[ja,torch]) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.9->transformers[ja,torch]) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch!=1.12.0,>=1.9->transformers[ja,torch]) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch!=1.12.0,>=1.9->transformers[ja,torch]) (16.0.6)\n","Collecting wasabi<1.0.0,>=0.6.0 (from unidic>=1.0.2->transformers[ja,torch])\n","  Downloading wasabi-0.10.1-py3-none-any.whl (26 kB)\n","Collecting plac<2.0.0,>=1.1.3 (from unidic>=1.0.2->transformers[ja,torch])\n","  Downloading plac-1.3.5-py2.py3-none-any.whl (22 kB)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2022.7.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch!=1.12.0,>=1.9->transformers[ja,torch]) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch!=1.12.0,>=1.9->transformers[ja,torch]) (1.3.0)\n","Building wheels for collected packages: ipadic, sudachidict-core, unidic, unidic-lite\n","  Building wheel for ipadic (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ipadic: filename=ipadic-1.0.0-py3-none-any.whl size=13556703 sha256=f78d81afcb554d9e21123cd19e3ad4e03e81d2ca2e865a3c50337b8d3d4bc05e\n","  Stored in directory: /root/.cache/pip/wheels/5b/ea/e3/2f6e0860a327daba3b030853fce4483ed37468bbf1101c59c3\n","  Building wheel for sudachidict-core (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sudachidict-core: filename=SudachiDict_core-20230110-py3-none-any.whl size=71665379 sha256=e3518861937b2d42064ab66207e485af034e8b68e7801fb3c0edbb584ec00313\n","  Stored in directory: /root/.cache/pip/wheels/35/35/8a/5cd8203a86e68ccefc49d4a2975165bb9ee369d2693eb4049b\n","  Building wheel for unidic (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for unidic: filename=unidic-1.1.0-py3-none-any.whl size=7409 sha256=a4a4bcbb5fa2d62ac1c47b116e2098bae10867448b44733ec668eefedd1509d5\n","  Stored in directory: /root/.cache/pip/wheels/7a/72/72/1f3d654c345ea69d5d51b531c90daf7ba14cc555eaf2c64ab0\n","  Building wheel for unidic-lite (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for unidic-lite: filename=unidic_lite-1.0.8-py3-none-any.whl size=47658818 sha256=9d86231bf5fbd92715ba571f0dc65e1e5ba1efcc868aa824c7732f86cabafd8c\n","  Stored in directory: /root/.cache/pip/wheels/89/e8/68/f9ac36b8cc6c8b3c96888cd57434abed96595d444f42243853\n","Successfully built ipadic sudachidict-core unidic unidic-lite\n","Installing collected packages: wasabi, unidic-lite, tokenizers, sudachipy, safetensors, plac, ipadic, faiss-cpu, xxhash, sudachidict-core, rhoknp, fugashi, dill, unidic, multiprocess, huggingface-hub, transformers, datasets, accelerate\n","  Attempting uninstall: wasabi\n","    Found existing installation: wasabi 1.1.2\n","    Uninstalling wasabi-1.1.2:\n","      Successfully uninstalled wasabi-1.1.2\n","Successfully installed accelerate-0.20.3 datasets-2.13.1 dill-0.3.6 faiss-cpu-1.7.4 fugashi-1.2.1 huggingface-hub-0.16.4 ipadic-1.0.0 multiprocess-0.70.14 plac-1.3.5 rhoknp-1.3.0 safetensors-0.3.1 sudachidict-core-20230110 sudachipy-0.6.7 tokenizers-0.13.3 transformers-4.30.2 unidic-1.1.0 unidic-lite-1.0.8 wasabi-0.10.1 xxhash-3.2.0\n"]}]},{"cell_type":"markdown","metadata":{"id":"g6qcZUyrA2Go"},"source":["#### データセットの読み込みと前処理"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":172,"referenced_widgets":["91a3bafa09884eaaab6035c2dfc5e0e3","fa4ccf82bd9e43988b16b83b30cbfc38","06faa58c4afe41da90316e1d78b87ceb","c8da44f0adea433c95b42ec6d82c0515","ca030c25510d4bf1bc5081df335e02fe","35d280b837804c8a83563296bbbfcbca","a30ef9ba80184f1ab0f126d667870899","91be530904d444c88e04b6fc7be9ab08","196f29c9130945c7833e47be148a98e5","e6651867239d48fdb581950e7a49ac1f","803ae89d073e4c8d952369094929c24c","a15f5a77dea24c35b8d51b8df7a8c358","592255fb29d04314b928ff1e71b13ede","0fded96081564ed88f6f7fec9a255f5c","1c1c487711864702866eda1685380363","76be5ee357a54c42b0de81470b7c99c9","15a794f7b23d4f619445214632046380","e5d3336bc9f14f3d97e59fe3b5482370","dae255282a9e4141a402aeea36991701","a56b1be5ffbe41eaa91b12cd23613011","acbf8f54fd7d411cb6378f4386895ba9","7cf41e1a4d3c4e808b80c86bfc771e78","c26a0c2192b144dd909174826b537e70","acc66de3e054488abba1ad75902a210e","c4e5ca6bbc16427c8ded55c0a66eb3fb","a54fc449100a4b8ba50daa2773ba9572","f9939d38c63248b1a3099033f1f5e73a","ff51956308574d6fbbe8857d126f1229","46076d2796214dd480b2f0220d886508","d28ba7ad7be345b2b2fb91273f4c3ce9","c37473102e9c45089f046a939ff768ee","cfda4e706ea249c5aa0196bbb41052b4","8422258fdec64c85ac2faeb523906b50","0bb59c6218d743c4bca13cc40a142316","8bb2373bccc2492a89f4b91f4002f06d","2825e8a9e3984809a2343565df4e1733","35410c24f4214884a919860384dbd299","79937c419f204d94af88a6ee82af76ab","e04c4d1d2dc9444586000752bab4a915","7e286329d6b94c509a25d95e07c66772","75a7231cbc7d4004a28d5e2171c66fad","24cf069432874007b29acbdc607907a8","bdbc5dc8d0414df7af8e18e1dcbcf216","b7b359899bc64432a4a128d8e813450b"]},"id":"KlOpsF0bA2Go","outputId":"d47c479b-e50f-4b4a-840c-ac3ea5a89518"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading builder script:   0%|          | 0.00/3.22k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"91a3bafa09884eaaab6035c2dfc5e0e3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading readme:   0%|          | 0.00/1.22k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a15f5a77dea24c35b8d51b8df7a8c358"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Downloading and preparing dataset jawiki-paragraphs/default to /root/.cache/huggingface/datasets/llm-book___jawiki-paragraphs/default/1.0.0/0f2d7acd99ad7ae0615fd07442dbd1654d37c5d60a39fc720efe28acff3f86f8...\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading data:   0%|          | 0.00/1.49G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c26a0c2192b144dd909174826b537e70"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating train split:   0%|          | 0/9668476 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0bb59c6218d743c4bca13cc40a142316"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Dataset jawiki-paragraphs downloaded and prepared to /root/.cache/huggingface/datasets/llm-book___jawiki-paragraphs/default/1.0.0/0f2d7acd99ad7ae0615fd07442dbd1654d37c5d60a39fc720efe28acff3f86f8. Subsequent calls will reuse this data.\n"]}],"source":["from datasets import load_dataset\n","\n","# Hugging Face Hubのllm-book/jawiki-paragraphsのリポジトリから\n","# Wikipediaの段落テキストのデータを読み込む\n","paragraph_dataset = load_dataset(\n","    \"llm-book/jawiki-paragraphs\", split=\"train\"\n",")"]},{"cell_type":"code","source":["# 段落データの形式と事例数を確認する\n","print(paragraph_dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O4xYz0Unmm7Z","outputId":"7cc74247-4613-46a2-c3c0-cbb068aaf513"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset({\n","    features: ['id', 'pageid', 'revid', 'paragraph_index', 'title', 'section', 'text', 'html_tag'],\n","    num_rows: 9668476\n","})\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_u4ljwwvA2Gp","outputId":"7f7cb4c4-f3dd-4d9f-d658-11bec1419d92"},"outputs":[{"output_type":"stream","name":"stdout","text":["{'html_tag': 'p',\n"," 'id': '5-89167474-0',\n"," 'pageid': 5,\n"," 'paragraph_index': 0,\n"," 'revid': 89167474,\n"," 'section': '__LEAD__',\n"," 'text': 'アンパサンド(&, 英語: '\n","         'ampersand)は、並立助詞「...と...」を意味する記号である。ラテン語で「...と...」を表す接続詞 \"et\" '\n","         'の合字を起源とする。現代のフォントでも、Trebuchet MS など一部のフォントでは、\"et\" '\n","         'の合字であることが容易にわかる字形を使用している。',\n"," 'title': 'アンパサンド'}\n","{'html_tag': 'p',\n"," 'id': '5-89167474-1',\n"," 'pageid': 5,\n"," 'paragraph_index': 1,\n"," 'revid': 89167474,\n"," 'section': '語源',\n"," 'text': '英語で教育を行う学校でアルファベットを復唱する場合、その文字自体が単語となる文字(\"A\", \"I\", かつては \"O\" '\n","         'も)については、伝統的にラテン語の per se(それ自体)を用いて \"A per se A\" '\n","         'のように唱えられていた。また、アルファベットの最後に、27番目の文字のように \"&\" を加えることも広く行われていた。\"&\" '\n","         'はラテン語で et と読まれていたが、後に英語で and と読まれるようになった。結果として、アルファベットの復唱の最後は \"X, Y, '\n","         'Z, and per se and\" という形になった。この最後のフレーズが繰り返されるうちに \"ampersand\" '\n","         'と訛っていき、この言葉は1837年までには英語の一般的な語法となった。',\n"," 'title': 'アンパサンド'}\n"]}],"source":["from pprint import pprint\n","\n","# 段落データの内容を確認する\n","pprint(paragraph_dataset[0])\n","pprint(paragraph_dataset[1])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17,"referenced_widgets":["fe1de8558de7436e9af49c8799f3ded9","17be1ab5a25b4cffa620205604083d73","ccab17fe6c8b43dc87966e24464b52a0","7336d6ed9c324175b0f5156278e715f8","13c3a7cfb4cb4a0fa79f3d9dc9e96b10","caaa57d6e1604dd081b2c143070e0bd8","035fb86c93fa4a059a64cac4e5e7a9b1","ed9006e77f6c47a4b977d5e759ba5e67","d2c9e0cd046248d4b6679aea8f9b8f90","ce2621a693754a22acbbf3882a537e6e","cef45d6b32974a29889eaf8b3371662f"]},"id":"2KkDog2vA2Gp","outputId":"ac4af24b-8115-4861-8c6a-382a83994de1"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Filter:   0%|          | 0/9668476 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe1de8558de7436e9af49c8799f3ded9"}},"metadata":{}}],"source":["# 段落データのうち、各記事の最初の段落のみを使うようにする\n","paragraph_dataset = paragraph_dataset.filter(\n","    lambda example: example[\"paragraph_index\"] == 0\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sas0HXR8A2Gp","outputId":"90e86800-5a89-47f0-a87e-06c3429652cc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset({\n","    features: ['id', 'pageid', 'revid', 'paragraph_index', 'title', 'section', 'text', 'html_tag'],\n","    num_rows: 1339236\n","})\n"]}],"source":["# フィルタリング後の段落データの形式と事例数を確認する\n","print(paragraph_dataset)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dG_OELbrA2Gq","outputId":"d68ebee3-b55a-417f-f8f2-e22b759376f6"},"outputs":[{"output_type":"stream","name":"stdout","text":["{'html_tag': 'p',\n"," 'id': '5-89167474-0',\n"," 'pageid': 5,\n"," 'paragraph_index': 0,\n"," 'revid': 89167474,\n"," 'section': '__LEAD__',\n"," 'text': 'アンパサンド(&, 英語: '\n","         'ampersand)は、並立助詞「...と...」を意味する記号である。ラテン語で「...と...」を表す接続詞 \"et\" '\n","         'の合字を起源とする。現代のフォントでも、Trebuchet MS など一部のフォントでは、\"et\" '\n","         'の合字であることが容易にわかる字形を使用している。',\n"," 'title': 'アンパサンド'}\n","{'html_tag': 'p',\n"," 'id': '10-94194440-0',\n"," 'pageid': 10,\n"," 'paragraph_index': 0,\n"," 'revid': 94194440,\n"," 'section': '__LEAD__',\n"," 'text': '言語(げんご)は、狭義には「声による記号の体系」をいう。',\n"," 'title': '言語'}\n"]}],"source":["# フィルタリング後の段落データの内容を確認する\n","pprint(paragraph_dataset[0])\n","pprint(paragraph_dataset[1])"]},{"cell_type":"markdown","source":["#### トークナイザとモデルの準備"],"metadata":{"id":"Nsv0n6prdUWS"}},{"cell_type":"markdown","source":["Hugging Face Hubから読み込む場合"],"metadata":{"id":"Ze1bUTOqdY31"}},{"cell_type":"code","source":["from transformers import AutoModel, AutoTokenizer\n","\n","# Hugging Face Hubにアップロードされた\n","# 教師なしSimCSEのトークナイザとエンコーダを読み込む\n","model_name = \"llm-book/bert-base-japanese-v3-unsup-simcse-jawiki\"\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","encoder = AutoModel.from_pretrained(model_name)"],"metadata":{"id":"BHvA_Yz1dfvg","colab":{"base_uri":"https://localhost:8080/","height":177,"referenced_widgets":["c264f3f9fbb641a4844e0638ca7c08fa","c487edc93ce34767ad574b621184f384","49ac1a605ae14905b206963ce9cc887a","7e91476c446f456dafdd74eca1303e1b","fda3db32c8a449c48985f7b1eea34844","eb8786ad107a4222985e2f0e0d9ba300","3601107b6a1c49ef8807a812950289ff","b74e11710ab7414283c1b70c82705da6","7feac5c10c6b4263a6001f5c270f1dc9","b6d160c4d01546acb098fba6453a88fd","3db9fa6eeef3435abd1a858067da2470","c0d4206060004bcb862d8220e935f48e","37df2ef6ae5e4b34bd524cc6ac3918ec","5252cb3df0b6495dadf0385e26b18b20","c25a1ae05fa74237a299ae98c6ccdd82","a2d3756ab4104f6f9c84776e0da13a63","a41f14cd803343aebdeae7139405fa54","aabf55842c564cc1a5ecc7b131b0e7bc","d4cf2c143f37489583fb09c4d4d57877","8da552499b744654b1a182b259b0a22a","5fc9cae6c1c5422b98946c8699400b04","2275d5126512420dbf7833b03fd42d8b","e21e8933aa6b4a7aaf37a23878d1c4af","587e5ad902ad461ead95a93b85a5caa0","c517fb11e7e64c9a9a5efe49952c73a5","38f29aba99c2470e8d099a30c05d869a","9ff5565f0bf74ab78d57b987a4cbf875","a65893ec474d4e1fa7eeaf9fd73d4cd1","adda1e327c3a40c3825a338f1cb60ad7","517e6cbb566e4e8bb7ef24495326bb1a","29ecbfe8af094057935f108c32314c2f","6fb8c0783c4b4cf287134345be257a24","4fa45874a0574e0e8337c6637d2161d1","ebf4247fc61441759f5711a9881fed75","7b779dcfb0c34a20bde72d39179c2d1d","4db4e1b54fd040e183ab02b021dc4746","919e22c4792046cca475dfd09178c4c7","1d51038f497840879e967cf376bdaabc","659cdcd17fb747579594184bbdee8d0c","02cbf38335d54eaa9c31ddf1869bdb26","b2b492dd16214b50805aa60af31beef8","9f7934df2fdd45048d71cbe7685e52f3","ff48020eaf4144f4abe86ddb85a151c4","af2fd8bf3c1b4406a797c7353e96f818","2fb23a8da75c4018bab6b65392245837","f97287a302804e799bef4709ae45139c","3069495d6f534cf187502489a1b16c6d","e8f9f6b0d0de45f392a8239b14242867","215de7d485b44e47b60504ff30713a26","9333b6fffc094994b694e28dbb3a6622","08e1a7a78bdc42d8bb3ca7e0de2119b6","0de4fae33999406a926f9587f1f6d9ac","64714d5ebc134ad3be4d6ea964955cb9","7715c8ef15be4eecbdf65258b65644ca","4d195ece00b14175b07235fa62e276fc"]},"outputId":"6cec99f5-4441-49d1-d801-f99aeb5a53be"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/529 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c264f3f9fbb641a4844e0638ca7c08fa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/231k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c0d4206060004bcb862d8220e935f48e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)cial_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e21e8933aa6b4a7aaf37a23878d1c4af"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/634 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ebf4247fc61441759f5711a9881fed75"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/445M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2fb23a8da75c4018bab6b65392245837"}},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"Ean1X4UEA2Gn"},"source":["Google ドライブに保存したモデルを読み込む場合"]},{"cell_type":"code","source":["from google.colab import drive\n","\n","drive.mount(\"drive\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5NcyMG-hTDba","outputId":"1ec59fea-b624-4fe7-b91f-2f9413106a82"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at drive\n"]}]},{"cell_type":"code","source":["!cp -r drive/MyDrive/llm-book/outputs_unsup_simcse ."],"metadata":{"id":"gQro4HvQbH_q"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9w0or33XCT3P"},"outputs":[],"source":["from transformers import AutoModel, AutoTokenizer\n","\n","# ディスクに保存された教師なしSimCSEのトークナイザとエンコーダを読み込む\n","model_path = \"outputs_unsup_simcse/encoder\"\n","tokenizer = AutoTokenizer.from_pretrained(model_path)\n","encoder = AutoModel.from_pretrained(model_path)"]},{"cell_type":"markdown","source":["共通の処理"],"metadata":{"id":"EkpoD1LHUzvC"}},{"cell_type":"code","source":["# 読み込んだモデルをGPUのメモリに移動させる\n","device = \"cuda:0\"\n","encoder = encoder.to(device)"],"metadata":{"id":"w4WExwsM_xv9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gpxsbt7xA2Gq"},"source":["#### モデルによる埋め込みの計算"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bv-04r7-A2Gr"},"outputs":[],"source":["import numpy as np\n","import torch\n","import torch.nn.functional as F\n","\n","def embed_texts(texts: list[str]) -> np.ndarray:\n","    \"\"\"SimCSEのモデルを用いてテキストの埋め込みを計算\"\"\"\n","    # テキストにトークナイザを適用\n","    tokenized_texts = tokenizer(\n","        texts,\n","        padding=True,\n","        truncation=True,\n","        max_length=128,\n","        return_tensors=\"pt\",\n","    ).to(device)\n","\n","    # トークナイズされたテキストをベクトルに変換\n","    with torch.inference_mode():\n","        with torch.cuda.amp.autocast():\n","            encoded_texts = encoder(\n","                **tokenized_texts\n","            ).last_hidden_state[:, 0]\n","\n","    # ベクトルをNumPyのarrayに変換\n","    emb = encoded_texts.cpu().numpy().astype(np.float32)\n","    # ベクトルのノルムが1になるように正規化\n","    emb = emb / np.linalg.norm(emb, axis=1, keepdims=True)\n","    return emb"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17,"referenced_widgets":["a91e839ae485498dbf5757644ed2c107","21651eaa2b0a46c5937c08073032b580","71e55c5a162c43cfaf768482af414553","e49e168e46214ccda3030dd0abe7aa4d","952cb1f3e6604954bd4709ba5d3deb52","1e0bae3979e84c60a707c600e713614b","d83a04060d8b450abd246f89fb003fa6","8f2312b37cfa46659c3335d0208433a1","301b82e0fbb946ceb81a1ef56060e5d3","76e039c00de546c2a7d653fd19606eca","c86e1a0cea8f44f2bc44d12b285354d1"]},"id":"Hb8B3OtHA2Gr","outputId":"12d05931-8697-4f62-f189-01cb0fb76c03"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/1339236 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a91e839ae485498dbf5757644ed2c107"}},"metadata":{}}],"source":["# 段落データのすべての事例に埋め込みを付与する\n","paragraph_dataset = paragraph_dataset.map(\n","    lambda examples: {\n","        \"embeddings\": list(embed_texts(examples[\"text\"]))\n","    },\n","    batched=True,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SPW-HgTfA2Gr","colab":{"base_uri":"https://localhost:8080/"},"outputId":"93547927-2795-4912-cc88-4dbba015eb06"},"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset({\n","    features: ['id', 'pageid', 'revid', 'paragraph_index', 'title', 'section', 'text', 'html_tag', 'embeddings'],\n","    num_rows: 1339236\n","})\n"]}],"source":["# 埋め込みを付与した段落データの形式と事例数を確認する\n","print(paragraph_dataset)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fRxtZGZKA2Gr","outputId":"994581ff-2b1c-49a5-9900-72771329985f","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["{'embeddings': [0.04253670945763588,\n","                -0.041921038180589676,\n","                -0.03232395276427269,\n","                0.01823267713189125,\n","                -0.06700421124696732,\n","                -0.060905277729034424,\n","                -0.0534023717045784,\n","                0.005872650071978569,\n","                0.005581581499427557,\n","                0.00042301995563320816,\n","                0.05438239127397537,\n","                -0.030172063037753105,\n","                -0.015410738065838814,\n","                -0.09762054681777954,\n","                0.031499966979026794,\n","                0.007067433558404446,\n","                0.004230297636240721,\n","                -0.018429215997457504,\n","                -0.07031217217445374,\n","                0.009732971899211407,\n","                0.006155171897262335,\n","                -0.03274840489029884,\n","                -0.008405999280512333,\n","                -0.023153288289904594,\n","                0.051212359219789505,\n","                0.04340992122888565,\n","                -0.046259116381406784,\n","                0.05987464636564255,\n","                -0.020380081608891487,\n","                0.04289441928267479,\n","                0.01666509173810482,\n","                0.016305185854434967,\n","                -0.026717115193605423,\n","                -0.23048225045204163,\n","                -0.04769939184188843,\n","                -0.04171598330140114,\n","                0.026586825028061867,\n","                -0.004828054923564196,\n","                0.03277105093002319,\n","                0.008691300638020039,\n","                0.026287656277418137,\n","                0.008627944625914097,\n","                0.011857344768941402,\n","                0.03615589067339897,\n","                -0.020430713891983032,\n","                -0.00746951624751091,\n","                0.062078434973955154,\n","                0.06717467308044434,\n","                0.010287292301654816,\n","                0.017537251114845276,\n","                0.008577081374824047,\n","                0.24095778167247772,\n","                -0.007486123591661453,\n","                0.0264737568795681,\n","                0.05771562084555626,\n","                0.020831430330872536,\n","                8.526305464329198e-05,\n","                0.004056260455399752,\n","                0.022380946204066277,\n","                -0.0253500584512949,\n","                -0.0013282083673402667,\n","                -0.009060852229595184,\n","                0.025025103241205215,\n","                0.0029547731392085552,\n","                0.037178441882133484,\n","                -0.02741803601384163,\n","                -0.07146456837654114,\n","                0.05722592771053314,\n","                -0.0930631160736084,\n","                0.0320083387196064,\n","                -0.015162289142608643,\n","                -0.0019231642363592982,\n","                0.006153687369078398,\n","                0.05009403079748154,\n","                -0.05572575703263283,\n","                -0.036588724702596664,\n","                0.004669312387704849,\n","                -0.015769638121128082,\n","                0.01132812350988388,\n","                -0.04417148604989052,\n","                0.044495001435279846,\n","                -0.05727778375148773,\n","                -0.025111857801675797,\n","                0.0001144230627687648,\n","                -0.06440987437963486,\n","                0.017622221261262894,\n","                -0.0563872754573822,\n","                0.017298107966780663,\n","                0.007077057845890522,\n","                -0.03736013546586037,\n","                0.02162403240799904,\n","                0.013331359252333641,\n","                0.06269430369138718,\n","                0.0012644546804949641,\n","                -0.06404654681682587,\n","                -0.02438705414533615,\n","                0.06497954577207565,\n","                -0.013456140644848347,\n","                -0.01651746593415737,\n","                -0.012988581322133541,\n","                -0.06917011737823486,\n","                0.04866410419344902,\n","                -0.04115369915962219,\n","                0.014896531589329243,\n","                -0.0067675793543457985,\n","                -0.0024698032066226006,\n","                -0.05836249142885208,\n","                0.0764198899269104,\n","                -0.013099746778607368,\n","                0.006452557630836964,\n","                -0.004067266825586557,\n","                0.02269410900771618,\n","                0.0012832818320021033,\n","                0.04763416200876236,\n","                0.011340392753481865,\n","                -0.01751580834388733,\n","                -0.035941071808338165,\n","                0.010069189593195915,\n","                -0.05189119651913643,\n","                -0.02620471641421318,\n","                -0.01536551583558321,\n","                0.026784397661685944,\n","                0.021115312352776527,\n","                0.028133999556303024,\n","                0.00032888390705920756,\n","                -0.05650700628757477,\n","                0.02375338226556778,\n","                0.04058380052447319,\n","                -0.013001544401049614,\n","                0.01737561635673046,\n","                0.016969041898846626,\n","                -0.040532372891902924,\n","                0.06730551272630692,\n","                -0.01773781143128872,\n","                -0.02498282864689827,\n","                -0.034051284193992615,\n","                0.0313183031976223,\n","                -0.021360298618674278,\n","                0.05989440530538559,\n","                -0.022125935181975365,\n","                0.0014621883165091276,\n","                0.018456101417541504,\n","                -0.056873563677072525,\n","                -0.0699414536356926,\n","                -0.029953228309750557,\n","                -0.009704993106424809,\n","                -0.024225298315286636,\n","                -0.043740760535001755,\n","                -0.04912187159061432,\n","                0.03335510194301605,\n","                0.03429045528173447,\n","                -0.022426128387451172,\n","                -0.012705856934189796,\n","                0.0575864315032959,\n","                0.023625703528523445,\n","                -0.08522452414035797,\n","                -0.014992821961641312,\n","                0.019628020003437996,\n","                0.05478682741522789,\n","                -0.04390208423137665,\n","                -0.011558933183550835,\n","                0.0076096742413938046,\n","                -0.009055170230567455,\n","                -0.00845178309828043,\n","                0.007340886630117893,\n","                0.0372321717441082,\n","                -0.024714691564440727,\n","                0.02679506130516529,\n","                -0.011615199968218803,\n","                -0.005509293172508478,\n","                -0.02323160693049431,\n","                -0.019660454243421555,\n","                0.0408584326505661,\n","                -0.022488955408334732,\n","                -0.0015193563885986805,\n","                -0.020058834925293922,\n","                -0.021330181509256363,\n","                0.096441350877285,\n","                0.04111436754465103,\n","                0.04678231105208397,\n","                0.057943835854530334,\n","                0.02473602443933487,\n","                0.0321863554418087,\n","                -0.039157554507255554,\n","                -0.013009880669414997,\n","                0.03236386924982071,\n","                0.008880652487277985,\n","                -0.04186864197254181,\n","                0.011171906255185604,\n","                -0.07010660320520401,\n","                -0.00722134904935956,\n","                0.040189195424318314,\n","                0.008088892325758934,\n","                0.03300675004720688,\n","                -0.0024361980613321066,\n","                0.007951602339744568,\n","                -0.05221208557486534,\n","                -0.008952696807682514,\n","                0.003470198018476367,\n","                -0.012965662404894829,\n","                -0.036232735961675644,\n","                0.004483919590711594,\n","                -0.03618409484624863,\n","                -0.003858915064483881,\n","                -0.0426780991256237,\n","                -0.010322262533009052,\n","                0.017980922013521194,\n","                0.015825917944312096,\n","                -0.06594876945018768,\n","                -0.03799726814031601,\n","                -0.055808670818805695,\n","                -0.02108766883611679,\n","                0.023558935150504112,\n","                -0.015796443447470665,\n","                0.004145211074501276,\n","                0.021486084908246994,\n","                0.016587600111961365,\n","                -0.03115653060376644,\n","                -0.014965861104428768,\n","                0.0038841268979012966,\n","                -0.018696390092372894,\n","                0.0494176410138607,\n","                -0.02478426694869995,\n","                0.00022548588458448648,\n","                -0.07037591189146042,\n","                -0.05456472188234329,\n","                0.032502613961696625,\n","                0.03350323066115379,\n","                0.014727277681231499,\n","                0.005044419318437576,\n","                -0.03395332768559456,\n","                0.024152535945177078,\n","                0.0161834005266428,\n","                0.02679445967078209,\n","                0.0047861249186098576,\n","                -0.026755651459097862,\n","                -0.00893386173993349,\n","                -0.007040482945740223,\n","                0.03307773917913437,\n","                -0.006365480832755566,\n","                0.011217710562050343,\n","                -0.01698109693825245,\n","                0.013734658248722553,\n","                -0.04332162067294121,\n","                -0.0056692673824727535,\n","                0.0281114112585783,\n","                0.005758299957960844,\n","                -0.03678525984287262,\n","                -0.001244321116246283,\n","                -0.04919593036174774,\n","                -0.026135656982660294,\n","                -0.014137673191726208,\n","                -0.04122152924537659,\n","                0.041230008006095886,\n","                -0.022700270637869835,\n","                0.05962074548006058,\n","                -0.034820955246686935,\n","                -0.011181985028088093,\n","                0.04318242147564888,\n","                -0.01466365810483694,\n","                0.02850806899368763,\n","                -0.04711481183767319,\n","                -0.0305564496666193,\n","                -0.021059272810816765,\n","                -0.02944490686058998,\n","                0.02372506447136402,\n","                0.07128474861383438,\n","                -0.05882326140999794,\n","                -0.04121209308505058,\n","                -0.052687324583530426,\n","                -0.060641609132289886,\n","                0.05146007612347603,\n","                0.007318533957004547,\n","                -0.04798059165477753,\n","                0.01315990462899208,\n","                -0.05176813155412674,\n","                -0.008077535778284073,\n","                0.01963447406888008,\n","                -0.014496161602437496,\n","                -0.04794296622276306,\n","                -0.036349717527627945,\n","                0.027350760996341705,\n","                -0.01310454960912466,\n","                0.02274859882891178,\n","                -0.07914416491985321,\n","                -0.000387741340091452,\n","                -0.01740678958594799,\n","                0.010112353600561619,\n","                -0.09135930985212326,\n","                -0.033595964312553406,\n","                0.008223187178373337,\n","                0.0023228833451867104,\n","                -0.01976715214550495,\n","                0.02284100465476513,\n","                0.006970856338739395,\n","                -0.016829289495944977,\n","                -0.04435359686613083,\n","                0.011810910888016224,\n","                0.016448602080345154,\n","                0.033209625631570816,\n","                -0.012257455848157406,\n","                -0.008296854794025421,\n","                0.006980961188673973,\n","                2.4419447072432376e-05,\n","                0.04477804899215698,\n","                -0.045641615986824036,\n","                -0.040871940553188324,\n","                0.006970750633627176,\n","                -0.08559396862983704,\n","                0.05882614105939865,\n","                0.012288589961826801,\n","                -0.031365588307380676,\n","                0.006352691445499659,\n","                0.00019435193098615855,\n","                0.07239284366369247,\n","                -0.028754688799381256,\n","                -0.014306926168501377,\n","                -0.018783502280712128,\n","                0.0025074086152017117,\n","                -0.0691041424870491,\n","                -0.029229409992694855,\n","                0.011953894980251789,\n","                0.0007165866554714739,\n","                -0.05039791390299797,\n","                0.02148599363863468,\n","                -0.0008051327895373106,\n","                0.010949229821562767,\n","                -0.08594092726707458,\n","                -0.03728775680065155,\n","                0.03752484172582626,\n","                0.02976871281862259,\n","                -0.034991294145584106,\n","                -0.03768168017268181,\n","                -0.04170661047101021,\n","                -0.07944554090499878,\n","                0.026647241786122322,\n","                0.011319159530103207,\n","                0.013004204258322716,\n","                -0.032302599400281906,\n","                -0.016853896901011467,\n","                -0.025429628789424896,\n","                -0.03714265301823616,\n","                0.003812868148088455,\n","                0.027952084317803383,\n","                -0.043428096920251846,\n","                0.0013409481616690755,\n","                -0.029049362987279892,\n","                0.0002520210691727698,\n","                0.02518663927912712,\n","                0.061494648456573486,\n","                -0.02034059725701809,\n","                0.05384057015180588,\n","                0.059738028794527054,\n","                0.06739916652441025,\n","                -0.03429277613759041,\n","                -0.01456468366086483,\n","                0.03392462059855461,\n","                0.022504111751914024,\n","                -0.0015234932070598006,\n","                0.002882120432332158,\n","                -0.06576831638813019,\n","                0.015038629062473774,\n","                -0.0003812761860899627,\n","                -0.016585398465394974,\n","                -0.05550443381071091,\n","                0.02394377812743187,\n","                0.05281613767147064,\n","                0.0034038678277283907,\n","                -0.015708448365330696,\n","                0.04055653512477875,\n","                0.04002326726913452,\n","                0.006562651135027409,\n","                -0.06465374678373337,\n","                0.009940196759998798,\n","                -0.049279116094112396,\n","                -0.03554235398769379,\n","                -0.012869494035840034,\n","                0.016105083748698235,\n","                0.04736262932419777,\n","                -0.022331397980451584,\n","                -0.002533386927098036,\n","                0.02403479814529419,\n","                -0.030697334557771683,\n","                -0.038407500833272934,\n","                -0.03319869935512543,\n","                -0.03150240704417229,\n","                -0.011735773645341396,\n","                0.01901279203593731,\n","                0.01082144770771265,\n","                0.017379045486450195,\n","                -0.03658921644091606,\n","                0.03280434384942055,\n","                0.005321084521710873,\n","                -0.003644257318228483,\n","                -0.03797784820199013,\n","                -0.017609724774956703,\n","                0.010859573259949684,\n","                0.00234318058937788,\n","                -0.019361745566129684,\n","                -0.005685566458851099,\n","                -0.0389680340886116,\n","                0.01606150157749653,\n","                -0.0026105912402272224,\n","                0.00832019280642271,\n","                0.007389168255031109,\n","                -0.012291640974581242,\n","                0.0090788584202528,\n","                -0.01280266884714365,\n","                0.01035972312092781,\n","                -0.03949858248233795,\n","                -0.024285539984703064,\n","                -0.008256891742348671,\n","                -0.020436864346265793,\n","                0.012565949000418186,\n","                -0.0003486954083200544,\n","                0.013238986022770405,\n","                0.024839937686920166,\n","                0.030120840296149254,\n","                0.015708277001976967,\n","                0.04920041188597679,\n","                -0.04006766900420189,\n","                -0.020704058930277824,\n","                0.004470516461879015,\n","                -0.03587133437395096,\n","                0.003915370907634497,\n","                0.0014767047250643373,\n","                -0.013212655670940876,\n","                0.005037619732320309,\n","                -0.018952488899230957,\n","                0.002490561455488205,\n","                0.09888067841529846,\n","                0.030938725918531418,\n","                -0.007854786701500416,\n","                0.02814442105591297,\n","                -0.01083347387611866,\n","                0.001433179248124361,\n","                0.001541803008876741,\n","                0.008865459822118282,\n","                -0.03417842835187912,\n","                0.032447826117277145,\n","                -0.003658185712993145,\n","                -0.05156205967068672,\n","                -0.0336657278239727,\n","                -0.0014795480528846383,\n","                -0.03631773963570595,\n","                -0.00781263504177332,\n","                -0.01828829199075699,\n","                0.03174327686429024,\n","                0.013703706674277782,\n","                0.028447316959500313,\n","                0.004733783658593893,\n","                -0.02068432793021202,\n","                0.026385297998785973,\n","                -0.004865712020546198,\n","                -0.033840764313936234,\n","                0.016326194629073143,\n","                0.0016687156166881323,\n","                0.03679623082280159,\n","                0.020797371864318848,\n","                0.06335572898387909,\n","                -0.00747294956818223,\n","                -0.01031431183218956,\n","                0.030193381011486053,\n","                -0.08900021761655807,\n","                0.12131036072969437,\n","                0.07000751793384552,\n","                -0.024445831775665283,\n","                -0.0016737730475142598,\n","                -0.056972868740558624,\n","                -0.008067373186349869,\n","                0.01359066367149353,\n","                -0.06266634166240692,\n","                -0.058920592069625854,\n","                -0.05236005410552025,\n","                -0.08395189791917801,\n","                -0.06781654804944992,\n","                -0.0056191710755229,\n","                -0.043999481946229935,\n","                0.037797026336193085,\n","                -0.022044578567147255,\n","                -0.019810108467936516,\n","                0.014639216475188732,\n","                -0.005132738966494799,\n","                0.04980075731873512,\n","                -0.028750013560056686,\n","                0.02974245883524418,\n","                0.01743166893720627,\n","                0.05559436231851578,\n","                0.008708968758583069,\n","                -0.022394996136426926,\n","                -0.023193906992673874,\n","                0.014858645386993885,\n","                -0.04295630380511284,\n","                0.02179720066487789,\n","                0.049814675003290176,\n","                -0.004264615010470152,\n","                0.007876437157392502,\n","                0.005929546430706978,\n","                0.010942177847027779,\n","                0.018056193366646767,\n","                0.03470192849636078,\n","                0.02556942217051983,\n","                0.008209073916077614,\n","                0.02364157699048519,\n","                -0.0033023073337972164,\n","                0.016569456085562706,\n","                0.007600875571370125,\n","                0.029734382405877113,\n","                0.08722792565822601,\n","                -0.040953148156404495,\n","                -0.02423223853111267,\n","                -0.0028209665324538946,\n","                0.031082145869731903,\n","                -0.01992107927799225,\n","                0.0002945591404568404,\n","                -0.03469209745526314,\n","                -0.024969488382339478,\n","                -0.033403586596250534,\n","                0.02317487820982933,\n","                -0.05547017976641655,\n","                0.008114095777273178,\n","                -0.01815931685268879,\n","                -0.025653358548879623,\n","                0.02592061646282673,\n","                0.041219692677259445,\n","                0.020962130278348923,\n","                -0.03647347539663315,\n","                0.04553815349936485,\n","                0.008324926719069481,\n","                0.03366522863507271,\n","                -0.006834655534476042,\n","                0.0639173686504364,\n","                -0.07297027856111526,\n","                0.0028792996890842915,\n","                0.030410557985305786,\n","                0.09134012460708618,\n","                0.04426344856619835,\n","                -0.006624505389481783,\n","                -0.005612586624920368,\n","                0.019418485462665558,\n","                -0.02038777805864811,\n","                0.039578620344400406,\n","                -0.04538425803184509,\n","                0.037961818277835846,\n","                0.016678007319569588,\n","                -0.015871787443757057,\n","                -0.057357024401426315,\n","                -0.022048579528927803,\n","                -0.025323830544948578,\n","                0.025302186608314514,\n","                0.015358627773821354,\n","                0.05117252469062805,\n","                0.006840735208243132,\n","                -0.019030330702662468,\n","                0.02373042330145836,\n","                0.009549605660140514,\n","                0.01827457919716835,\n","                -0.010911333374679089,\n","                -0.060430195182561874,\n","                0.018251650035381317,\n","                0.015014718286693096,\n","                0.0011037165531888604,\n","                -0.01178948674350977,\n","                0.0189718808978796,\n","                -0.004828990437090397,\n","                -0.012270179577171803,\n","                0.01925327256321907,\n","                -0.032658446580171585,\n","                -0.023100966587662697,\n","                -0.0067337010987102985,\n","                -0.0020815765019506216,\n","                0.026417605578899384,\n","                0.0391182079911232,\n","                0.04046023637056351,\n","                0.006079308222979307,\n","                -0.04940316453576088,\n","                -0.03933168575167656,\n","                -0.023814339190721512,\n","                0.018881993368268013,\n","                -0.04976043850183487,\n","                -0.0072515783831477165,\n","                0.009218154475092888,\n","                0.021623943001031876,\n","                0.018297724425792694,\n","                -0.01062388438731432,\n","                0.012162255123257637,\n","                -0.002508177887648344,\n","                -0.0006066004862077534,\n","                -0.04308546707034111,\n","                0.009238115511834621,\n","                0.042677026242017746,\n","                0.00981613714247942,\n","                0.03536960482597351,\n","                -0.03549661487340927,\n","                -0.024661323055624962,\n","                -0.04012841731309891,\n","                -0.003978608176112175,\n","                0.03929929435253143,\n","                -0.002920260187238455,\n","                -0.005199064966291189,\n","                -0.02177436836063862,\n","                0.030672162771224976,\n","                -0.05012527480721474,\n","                -0.013386573642492294,\n","                0.027710409834980965,\n","                0.010156814940273762,\n","                -0.027236951515078545,\n","                -0.03247779607772827,\n","                0.018633659929037094,\n","                0.068936288356781,\n","                -0.023752670735120773,\n","                0.0723956972360611,\n","                -0.02297849766910076,\n","                -0.005994682665914297,\n","                -0.02781030721962452,\n","                -0.0364067405462265,\n","                -0.07204010337591171,\n","                0.04712189733982086,\n","                -0.009432659484446049,\n","                -0.00022050857660360634,\n","                -0.01243174634873867,\n","                -0.04090357571840286,\n","                0.03165046498179436,\n","                -0.03181310370564461,\n","                0.034722950309515,\n","                -0.04043734446167946,\n","                0.03496278077363968,\n","                -0.046392083168029785,\n","                0.040211256593465805,\n","                -0.012164659798145294,\n","                0.003595034359022975,\n","                0.023555392399430275,\n","                -0.011838763020932674,\n","                0.04062953591346741,\n","                0.029329968616366386,\n","                -0.03910014405846596,\n","                0.027838533744215965,\n","                -0.009381362237036228,\n","                -0.007774665020406246,\n","                0.04384215921163559,\n","                0.07762059569358826,\n","                0.046007510274648666,\n","                -0.04042528569698334,\n","                -0.03293289989233017,\n","                -0.019135823473334312,\n","                -0.01996942237019539,\n","                -0.006861846894025803,\n","                -0.024829212576150894,\n","                0.0395975336432457,\n","                0.013086420483887196,\n","                0.03789309784770012,\n","                0.01417109090834856,\n","                -0.001768608228303492,\n","                -0.001971994759514928,\n","                -0.012113712728023529,\n","                -0.0026062936522066593,\n","                0.019702287390828133,\n","                -0.032026976346969604,\n","                -0.09198902547359467,\n","                0.04469511657953262,\n","                -0.03431355953216553,\n","                0.03427394479513168,\n","                -0.0017761553172022104,\n","                0.00795702263712883,\n","                0.013667873106896877,\n","                -0.02173018828034401,\n","                -0.008869331330060959,\n","                0.025615107268095016,\n","                0.03646840527653694,\n","                0.04788123443722725,\n","                -0.02239488624036312,\n","                -0.028080705553293228,\n","                -0.0635528415441513,\n","                0.015162994153797626,\n","                0.057772181928157806,\n","                -0.023475464433431625,\n","                0.02004474587738514,\n","                0.0256247129291296,\n","                -0.017512600868940353,\n","                -0.031741391867399216,\n","                0.04740189388394356,\n","                0.02469581738114357,\n","                0.04363298416137695,\n","                -0.012786392122507095,\n","                0.0181017704308033,\n","                -0.042142242193222046,\n","                0.006416501943022013,\n","                0.013363960199058056,\n","                -0.005181646440178156,\n","                0.04413206875324249,\n","                0.015485976822674274,\n","                -0.01078968308866024,\n","                0.011364659294486046,\n","                0.04253309220075607,\n","                -0.010323375463485718,\n","                -0.02783501148223877,\n","                0.04653259739279747,\n","                0.07014897465705872,\n","                0.010183088481426239,\n","                -0.0056650228798389435,\n","                0.019051287323236465,\n","                -0.0140976682305336,\n","                -0.015592816285789013,\n","                -0.005865105893462896,\n","                -0.0008683954365551472,\n","                0.01049695536494255,\n","                0.006110446527600288,\n","                0.06692809611558914,\n","                -0.019280273467302322,\n","                -0.05711463838815689,\n","                0.021755913272500038,\n","                0.008821746334433556,\n","                -0.053558580577373505,\n","                -0.032653097063302994,\n","                -0.021437013521790504,\n","                0.07387468218803406,\n","                -0.001574910245835781,\n","                0.02301197312772274,\n","                0.016244525089859962,\n","                -0.02942698262631893,\n","                -0.05030298978090286,\n","                -0.0021458587143570185,\n","                0.0028164968825876713,\n","                0.004437414929270744,\n","                -0.019820060580968857,\n","                0.06273549795150757,\n","                0.022206241264939308,\n","                0.001571784378029406,\n","                -0.019627956673502922,\n","                -0.011303343810141087,\n","                0.013038711622357368,\n","                -0.00842222012579441,\n","                0.044637516140937805,\n","                0.026289651170372963,\n","                -0.008502472192049026,\n","                -0.055131033062934875,\n","                -0.06173963099718094,\n","                -0.010547947138547897,\n","                -0.021414611488580704,\n","                0.059927310794591904,\n","                -0.005345406010746956,\n","                0.044722530990839005,\n","                -0.03405184671282768,\n","                -0.004974812734872103,\n","                -0.04094124212861061,\n","                0.023741737008094788,\n","                0.01702318899333477,\n","                0.03724083676934242,\n","                -0.018934132531285286,\n","                0.04437673091888428,\n","                0.03112228587269783,\n","                -0.10487285256385803,\n","                -0.05282636359333992,\n","                -0.021144429221749306,\n","                0.026769770309329033,\n","                0.016101792454719543,\n","                -0.00048609086661599576,\n","                -0.021915148943662643,\n","                0.028846697881817818,\n","                0.04655158147215843,\n","                -0.01673867553472519,\n","                -0.003771623130887747,\n","                0.008606340736150742,\n","                -0.01346861943602562,\n","                0.006959658116102219,\n","                -0.023598121479153633,\n","                -0.0010074099991470575,\n","                0.001247039414010942],\n"," 'html_tag': 'p',\n"," 'id': '5-89167474-0',\n"," 'pageid': 5,\n"," 'paragraph_index': 0,\n"," 'revid': 89167474,\n"," 'section': '__LEAD__',\n"," 'text': 'アンパサンド(&, 英語: '\n","         'ampersand)は、並立助詞「...と...」を意味する記号である。ラテン語で「...と...」を表す接続詞 \"et\" '\n","         'の合字を起源とする。現代のフォントでも、Trebuchet MS など一部のフォントでは、\"et\" '\n","         'の合字であることが容易にわかる字形を使用している。',\n"," 'title': 'アンパサンド'}\n"]}],"source":["# 埋め込みを計算した段落データの内容を確認する\n","pprint(paragraph_dataset[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"referenced_widgets":["6a5028e4beee43ff956e779759f69849","1bd9f31ede00469d979e279ac799592e","4a3a90ddec81429c945cfe16fa755936","4027caa549304ada9646474b1804f3a5","ed50272e3d764e7c966293815cf358d3","c992fb8525c94ead9caedefcbe23b9a5","cd5df5f9e78f47f88b90c4c78ccf84a9","b97a66f4c1104f48b2774b0961d73063","a2846b64242f43a1a39cf7229ac7efa2","a2f3be4259df43c4b2bcb097fb1df348","5d94831627f7445fb2cd7be3da843940"],"base_uri":"https://localhost:8080/","height":17},"id":"bRFWUXpuA2Gs","outputId":"1eb54c0b-3691-4bd3-c339-18d50159ac54"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Saving the dataset (0/10 shards):   0%|          | 0/1339236 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6a5028e4beee43ff956e779759f69849"}},"metadata":{}}],"source":["# 埋め込みを付与した段落データをディスクに保存する\n","paragraph_dataset.save_to_disk(\n","    \"outputs_unsup_simcse/embedded_paragraphs\"\n",")"]},{"cell_type":"markdown","metadata":{"id":"_3cRuXKtA2Gs"},"source":["#### Google ドライブへの保存"]},{"cell_type":"code","source":["from google.colab import drive\n","\n","drive.mount(\"drive\")"],"metadata":{"id":"y0KmEV37YXlK"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nwWTao78A2Gs"},"outputs":[],"source":["# 保存された段落データをGoogleドライブのフォルダにコピーする\n","!cp -r outputs_unsup_simcse/embedded_paragraphs drive/MyDrive/llm-book/outputs_unsup_simcse"]},{"cell_type":"markdown","metadata":{"id":"Z8N5T7QIA2Gt"},"source":["#### `Faiss` による最近傍探索を試す"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":126,"referenced_widgets":["b4237071937649519d1abb8bda5c7191","ae712ee6726d4cff81d8e3227cdbbf8c","e59bfc97c9a144fbbb73935d6f50bb23","52033f6bb9ca42a89870d3f104455854","773e7afa5c13429bb96197bdee284bf5","61e0080761dc4670a7aafdfb8d37f61c","e77c21df12ea4ac28fec604d90428852","f0e9d435692741f78ac17f09a571dad1","b0f475dfcd964ede94a0e85fd687a74d","c2b1e970ed3d4f4295e0b4b510308ca5","045d147d72294276901b6a8fdf18dc3b"]},"id":"bNez-6Q2A2Gt","outputId":"e526cdee-3e25-44dc-b19b-799486273d4f"},"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1340 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b4237071937649519d1abb8bda5c7191"}},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["Dataset({\n","    features: ['id', 'pageid', 'revid', 'paragraph_index', 'title', 'section', 'text', 'html_tag', 'embeddings'],\n","    num_rows: 1339236\n","})"]},"metadata":{},"execution_count":17}],"source":["import faiss\n","\n","# ベクトルの次元数をエンコーダの設定値から取り出す\n","emb_dim = encoder.config.hidden_size\n","# ベクトルの次元数を指定して空のFaissインデックスを作成する\n","index = faiss.IndexFlatIP(emb_dim)\n","# 段落データの\"embeddings\"フィールドのベクトルからFaissインデックスを構築する\n","paragraph_dataset.add_faiss_index(\"embeddings\", custom_index=index)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q41CyKXxA2Gt","colab":{"base_uri":"https://localhost:8080/"},"outputId":"a779ed98-3a90-49a7-ae72-942ff1a769fd"},"outputs":[{"output_type":"stream","name":"stdout","text":["0.78345203 日本の言語 日本の言語(にほんのげんご)は、日本の国土で使用されている言語について記述する。日本#言語も参照。\n","0.75877357 日本語教育 日本語教育(にほんごきょういく)とは、外国語としての日本語、第二言語としての日本語についての教育の総称である。\n","0.7494176 日本語学 日本語学(にほんごがく)とは、日本語を研究の対象とする学問である。\n","0.74729466 日本語 日本語(にほんご、にっぽんご、英語: Japanese)は、日本国内や、かつての日本領だった国、そして国外移民や移住者を含む日本人同士の間で使用されている言語。日本は法令によって公用語を規定していないが、法令その他の公用文は全て日本語で記述され、各種法令において日本語を用いることが規定され、学校教育においては「国語」の教科として学習を行う等、事実上、日本国内において唯一の公用語となっている。\n","0.7045407 国語 (教科) 国語(こくご、英: Japanese Language)は、日本の学校教育における教科の一つ。\n","0.7029643 和製英語 和製英語(わせいえいご)は、日本語の中で使われる和製外来語の一つで、日本で日本人により作られた、英語の言葉や英語に似ている言葉(固有名詞や商品名などを除く)である。英語圏では別表現をするために理解されなかったり、もしくは、全く異なった解釈をされたりする場合がある。\n","0.6956495 口語 口語(こうご)とは、普通の日常的な生活の中での会話で用いられる言葉遣いのことである。書記言語で使われる文語と違い、方言と呼ばれる地域差や社会階層などによる言語変種が応じやすく、これらと共通語などを使い分ける状態はダイグロシアと呼ばれる。\n","0.6944481 ジャパン ジャパン(英語: Japan)は、英語で日本を意味する単語。\n","0.6911353 日本語学科 日本語学科(にほんごがっか)とは、日本語を教育研究することを目的として大学や専門学校などの高等教育機関に置かれる学科の名称である。\n","0.6908301 日本語学校 日本語学校(にほんごがっこう)とは、主に日本語を母語としない者を対象として、第二言語・外国語としての日本語教育を実施する機関。日本国内外に存在している。\n"]}],"source":["query_text = \"日本語は、主に日本で話されている言語である。\"\n","\n","# 最近傍探索を実行し、類似度上位10件の事例とスコアを取得する\n","scores, retrieved_examples = paragraph_dataset.get_nearest_examples(\n","    \"embeddings\", embed_texts([query_text])[0], k=10\n",")\n","# 取得した事例の内容をスコアとともに表示する\n","titles = retrieved_examples[\"title\"]\n","texts = retrieved_examples[\"text\"]\n","for score, title, text in zip(scores, titles, texts):\n","    print(score, title, text)"]},{"cell_type":"markdown","source":["## 8.3 文埋め込みモデルの実装"],"metadata":{"id":"fFc6DN6dXmcU"}},{"cell_type":"markdown","source":["### 8.3.1 教師なしSimCSEの実装"],"metadata":{"id":"T9tm6Iv85FV8"}},{"cell_type":"markdown","metadata":{"id":"FzgcF-Vm0jzY"},"source":["#### 準備"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5TdiqcDcDhLf","outputId":"1d37ff0c-8b45-4e15-b7db-362944971ac9","tags":[]},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting datasets\n","  Downloading datasets-2.13.1-py3-none-any.whl (486 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/486.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m486.2/486.2 kB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.10.1)\n","Collecting transformers[ja,torch]\n","  Downloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m97.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.22.4)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n","Collecting dill<0.3.7,>=0.3.0 (from datasets)\n","  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.27.1)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.65.0)\n","Collecting xxhash (from datasets)\n","  Downloading xxhash-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting multiprocess (from datasets)\n","  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.4)\n","Collecting huggingface-hub<1.0.0,>=0.11.0 (from datasets)\n","  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[ja,torch]) (3.12.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[ja,torch]) (2022.10.31)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers[ja,torch])\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m75.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors>=0.3.1 (from transformers[ja,torch])\n","  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m49.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch!=1.12.0,>=1.9 in /usr/local/lib/python3.10/dist-packages (from transformers[ja,torch]) (2.0.1+cu118)\n","Collecting accelerate>=0.20.2 (from transformers[ja,torch])\n","  Downloading accelerate-0.20.3-py3-none-any.whl (227 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.6/227.6 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting fugashi>=1.0 (from transformers[ja,torch])\n","  Downloading fugashi-1.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (599 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m599.9/599.9 kB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting ipadic<2.0,>=1.0.0 (from transformers[ja,torch])\n","  Downloading ipadic-1.0.0.tar.gz (13.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m72.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting unidic-lite>=1.0.7 (from transformers[ja,torch])\n","  Downloading unidic-lite-1.0.8.tar.gz (47.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.4/47.4 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting unidic>=1.0.2 (from transformers[ja,torch])\n","  Downloading unidic-1.1.0.tar.gz (7.7 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting sudachipy>=0.6.6 (from transformers[ja,torch])\n","  Downloading SudachiPy-0.6.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m67.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting sudachidict-core>=20220729 (from transformers[ja,torch])\n","  Downloading SudachiDict-core-20230110.tar.gz (9.0 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting rhoknp<1.3.1,>=1.1.0 (from transformers[ja,torch])\n","  Downloading rhoknp-1.3.0-py3-none-any.whl (86 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.20.2->transformers[ja,torch]) (5.9.5)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.0.12)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.7.1)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (1.26.16)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.5.7)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.9->transformers[ja,torch]) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.9->transformers[ja,torch]) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.9->transformers[ja,torch]) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.9->transformers[ja,torch]) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch!=1.12.0,>=1.9->transformers[ja,torch]) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch!=1.12.0,>=1.9->transformers[ja,torch]) (16.0.6)\n","Collecting wasabi<1.0.0,>=0.6.0 (from unidic>=1.0.2->transformers[ja,torch])\n","  Downloading wasabi-0.10.1-py3-none-any.whl (26 kB)\n","Collecting plac<2.0.0,>=1.1.3 (from unidic>=1.0.2->transformers[ja,torch])\n","  Downloading plac-1.3.5-py2.py3-none-any.whl (22 kB)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2022.7.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch!=1.12.0,>=1.9->transformers[ja,torch]) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch!=1.12.0,>=1.9->transformers[ja,torch]) (1.3.0)\n","Building wheels for collected packages: ipadic, sudachidict-core, unidic, unidic-lite\n","  Building wheel for ipadic (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ipadic: filename=ipadic-1.0.0-py3-none-any.whl size=13556703 sha256=f03ac89d42968b8426c6517199fae22458b0cc834536491cbdedbccbf846fd55\n","  Stored in directory: /root/.cache/pip/wheels/5b/ea/e3/2f6e0860a327daba3b030853fce4483ed37468bbf1101c59c3\n","  Building wheel for sudachidict-core (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sudachidict-core: filename=SudachiDict_core-20230110-py3-none-any.whl size=71665379 sha256=38c08286212875e5c6ec6c11b54cf6990547c8e3738ee4cf5aefdfe0ef04ddfc\n","  Stored in directory: /root/.cache/pip/wheels/35/35/8a/5cd8203a86e68ccefc49d4a2975165bb9ee369d2693eb4049b\n","  Building wheel for unidic (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for unidic: filename=unidic-1.1.0-py3-none-any.whl size=7409 sha256=afe7086e3d15dbb8679ca6111947d957d7149075a3d7b2a148f6c076fd4a0456\n","  Stored in directory: /root/.cache/pip/wheels/7a/72/72/1f3d654c345ea69d5d51b531c90daf7ba14cc555eaf2c64ab0\n","  Building wheel for unidic-lite (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for unidic-lite: filename=unidic_lite-1.0.8-py3-none-any.whl size=47658818 sha256=78d631af267bb114407d6705b57c0afb0a7fea9d7ff24b9e7431e0516a99f80e\n","  Stored in directory: /root/.cache/pip/wheels/89/e8/68/f9ac36b8cc6c8b3c96888cd57434abed96595d444f42243853\n","Successfully built ipadic sudachidict-core unidic unidic-lite\n","Installing collected packages: wasabi, unidic-lite, tokenizers, sudachipy, safetensors, plac, ipadic, xxhash, sudachidict-core, rhoknp, fugashi, dill, unidic, multiprocess, huggingface-hub, transformers, datasets, accelerate\n","  Attempting uninstall: wasabi\n","    Found existing installation: wasabi 1.1.2\n","    Uninstalling wasabi-1.1.2:\n","      Successfully uninstalled wasabi-1.1.2\n","Successfully installed accelerate-0.20.3 datasets-2.13.1 dill-0.3.6 fugashi-1.2.1 huggingface-hub-0.16.4 ipadic-1.0.0 multiprocess-0.70.14 plac-1.3.5 rhoknp-1.3.0 safetensors-0.3.1 sudachidict-core-20230110 sudachipy-0.6.7 tokenizers-0.13.3 transformers-4.30.2 unidic-1.1.0 unidic-lite-1.0.8 wasabi-0.10.1 xxhash-3.2.0\n"]}],"source":["# 必要なパッケージをインストールする\n","!pip install datasets scipy transformers[ja,torch]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IP7_WoXTC06M","tags":[]},"outputs":[],"source":["from transformers.trainer_utils import set_seed\n","\n","# 乱数のシードを設定する\n","set_seed(42)"]},{"cell_type":"markdown","metadata":{"id":"6QVueYtb0jzd"},"source":["#### データセットの読み込みと前処理"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":172,"referenced_widgets":["685756b1f07e4afb93a3f2c164a820e2","c6fb1d8f765540c7bbd39098f94430c7","19b1c0cd984f471ab41341f36f8ffbc3","17f31cc3e28745cc939b10801e411c4c","b7991d7bb4fb4ec5983bddbebfb748cf","cad76d833aa54485a34b783cca59033e","e6d0519280e34c0a87c83ad1b3a6f7c5","f541568c87f844cebb367a7222f30e09","ea1ff3bfe4b3427c87f21eb85c619537","88076988ccc04da1a2daed92aa39e67a","96bbf0677c704246aa770525ec829e2b","66cda8ca0fbd4760941969a52b35fd0a","0eb945074d0b441a88a7f17770cced3d","16c4c0182c524b008fe1bedca1a7e21e","d2db804c528c424099a43e0c1ad0ea35","63bccf1b625047c4a369ddc54f666c47","c4cc2f2ac35f415d8f78343a124b8b48","6c1ca5ba414f4155b7cd8fecf19b7ed2","3339f008b6864e7b87a0516971ec8158","b213a91a1e9746ca9bf59a777286de6c","559a525571be43a69523bc3569ff0de5","e6739ab05a1e4f3ea6bca6911a78bb12","229dd620adf5441c90a03cb38ade78a7","4e460bc372f14a7f81d4e0d5aa76f6f2","8240e7bc9b494a24b172d40c6803d4e1","09e9ed439c214589a6610522e8123806","c41d3727f8154e409eeeaa8badd8742f","4c58af5b9e6f49759b9e39b11f9ec600","ca11f9fc0bb64f07973e7b0e354f2a80","0b8a0f7e5e1e42589e6d18fe70a5c44e","99c048709fde4705a8a6ffde67b32ded","b77ba7f170644d2999d49794ea4bd345","bb4b15f890144f0cb4678ac09b6dead8","65a4ab80957e4dda9113410d8d391edf","7f2e20b4ed4b4482b45878505a6c746c","f9cfa45ad3404a0e8533b6ea22adfab1","3a8df4367eb945298996ace67792a1f4","3451d81002ca4c0f86b8e13f6b79a273","84fab4185456407c9e683c4e036e4625","ccded65506694e9ebd5616b019edb238","a9705d3b1fc24864b1b6586bb1463145","8abc8ee0bd0e41f58462186b1a3a2aab","2edb373aa08749d99b4ec476a93fd5ab","6427d4eebf214433b5b24027da290480"]},"id":"M0qvWRzRFH_v","outputId":"5615e033-53ac-4596-c75e-3f9804c8f32e","tags":[]},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading builder script:   0%|          | 0.00/2.80k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"685756b1f07e4afb93a3f2c164a820e2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading readme:   0%|          | 0.00/969 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"66cda8ca0fbd4760941969a52b35fd0a"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Downloading and preparing dataset jawiki-sentences/default to /root/.cache/huggingface/datasets/llm-book___jawiki-sentences/default/1.0.0/9ffd2ffb1fc789ae54454c9279182964ae91a31003da241385388870f8c1f3e7...\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading data:   0%|          | 0.00/1.30G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"229dd620adf5441c90a03cb38ade78a7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating train split:   0%|          | 0/24387500 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"65a4ab80957e4dda9113410d8d391edf"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Dataset jawiki-sentences downloaded and prepared to /root/.cache/huggingface/datasets/llm-book___jawiki-sentences/default/1.0.0/9ffd2ffb1fc789ae54454c9279182964ae91a31003da241385388870f8c1f3e7. Subsequent calls will reuse this data.\n"]}],"source":["from datasets import load_dataset\n","\n","# Hugging Face Hubのllm-book/jawiki-sentencesのリポジトリから\n","# Wikipediaの文のデータを読み込み、SimCSEの訓練セットとして使用する\n","unsup_train_dataset = load_dataset(\n","    \"llm-book/jawiki-sentences\", split=\"train\"\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nYXnYYN62yOe","outputId":"c62eb791-75ad-4e85-b1c4-530163fe8535","tags":[]},"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset({\n","    features: ['text'],\n","    num_rows: 24387500\n","})\n"]}],"source":["# 訓練セットの形式と事例数を確認する\n","print(unsup_train_dataset)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZLIfnm-gF8wb","outputId":"d56ad1ff-ee51-4ce7-8fde-d1ac32b00d88","tags":[]},"outputs":[{"output_type":"stream","name":"stdout","text":["0 アンパサンド(&, 英語: ampersand)は、並立助詞「...と...」を意味する記号である。\n","1 ラテン語で「...と...」を表す接続詞 \"et\" の合字を起源とする。\n","2 現代のフォントでも、Trebuchet MS など一部のフォントでは、\"et\" の合字であることが容易にわかる字形を使用している。\n","3 英語で教育を行う学校でアルファベットを復唱する場合、その文字自体が単語となる文字(\"A\", \"I\", かつては \"O\" も)については、伝統的にラテン語の per se(それ自体)を用いて \"A per se A\" のように唱えられていた。\n","4 また、アルファベットの最後に、27番目の文字のように \"&\" を加えることも広く行われていた。\n","5 \"&\" はラテン語で et と読まれていたが、後に英語で and と読まれるようになった。\n","6 結果として、アルファベットの復唱の最後は \"X, Y, Z, and per se and\" という形になった。\n","7 この最後のフレーズが繰り返されるうちに \"ampersand\" と訛っていき、この言葉は1837年までには英語の一般的な語法となった。\n","8 アンドレ=マリ・アンペールがこの記号を自身の著作で使い、これが広く読まれたため、この記号が \"Ampère's and\" と呼ばれるようになったという誤った語源俗説がある。\n","9 アンパサンドの起源は1世紀の古ローマ筆記体にまで遡ることができる。\n","10 古ローマ筆記体では、E と T はしばしば合字として繋げて書かれていた(左図「アンパサンドの変遷」の字形1)。それに続く、流麗さを増した新ローマ筆記体では、様々な合字が極めて頻繁に使われるようになった。\n","11 字形2と3は4世紀中頃における et の合字の例である。\n","12 その後、9世紀のカロリング小文字体に至るラテン文字の変遷の過程で、合字の使用は一般には廃れていった。\n","13 しかし、et の合字は使われ続け、次第に元の文字がわかりにくい字形に変化していった(字形4から6)。\n","14 現代のイタリック体のアンパサンドは、ルネサンス期に発展した筆記体での et の合字に遡る。\n","15 1455年のヨーロッパにおける印刷技術の発明以降、印刷業者はイタリック体とローマ筆記体のアンパサンドの両方を多用するようになった。\n","16 アンパサンドのルーツはローマ時代に遡るため、ラテンアルファベットを使用する多くの言語でアンパサンドが使用されるようになった。\n","17 アンパサンドはしばしばラテンアルファベットの最後の文字とされることがあった。\n","18 例えば1011年のByrhtferthの文字表がその例である。\n","19 同様に、\"&\" は英語アルファベットの27番目の文字とされ、アメリカ合衆国やその他の地域でも、子供達はアンパサンドはアルファベットの最後の文字だと教えられていた。\n","20 1863年の M. B. Moore の著書 The Dixie Primer, for the Little Folks にその一例を見ることができる。\n","21 ジョージ・エリオットは、1859年に発表した小説「アダム・ビード(英語版)」の中で、Jacob Storey に次のセリフを語らせている。\n","22 \"He thought it [Z] had only been put to finish off th' alphabet like; though ampusand would ha' done as well, for what he could see.\" よく知られた童謡の Apple Pie ABC は \"X, Y, Z, and ampersand, All wished for a piece in hand\" という歌詞で締めくくられる。\n","23 アンパサンドは、ティロ式記号の et (\"⁊\", Unicode U+204A) とは別のものである。\n","24 ティロ式記号の et は、アンパサンドと意味は同じだが数字の「7」に似た形の記号である。\n","25 両者はともに古代から使用され、中世を通してラテン語の et を表すために使用された。\n","26 しかし、アンパサンドとティロ式記号の et はそれぞれ独立に発明されたものである。\n","27 ラテン文字から発展した古アイルランド語の文字では、アイルランド語の agus(「...と...」)を表すためにティロ式記号の et が使用されていた。\n","28 今日はゲール文字の一部として主に装飾的な目的で使用されている。\n","29 この文字はアイルランドにおけるキリスト教時代初期に修道院の影響によって書き文字に加わった可能性がある。\n","30 日常的な手書きの場合、欧米では小文字の ε(エプシロン)を大きくしたもの(あるいは数字の \"3\" の鏡文字)に縦線を加えた形の単純化されたアンパサンドがしばしば使われる。\n","31 また、エプシロンの上下に縦線または点を付けたものもしばしば使われる。\n","32 くだけた用法として、プラス記号(\"+\", この記号もまた et の合字である)がアンパサンドの代わりに使われることもある。\n","33 また、プラス記号に輪を重ねたような、無声歯茎側面摩擦音を示す発音記号「[ɬ]」のようなものが使われることもある。\n","34 ティロの速記には「et」を表すための「⁊」(U+204A Tironian sign et)がある。\n","35 この文字はドイツのフラクトゥールで使われたほか、ゲール文字でも使用される。\n","36 ギリシア文字では「......と」を意味するκαιを表すための合字として「ϗ」(U+03D7 Greek kai symbol)が使われることがある。\n","37 プログラミング言語では、C など多数の言語で AND 演算子として用いられる。\n","38 PHPでは、変数宣言記号($)の直前に記述することで、参照渡しを行うことができる。\n","39 BASIC 系列の言語では文字列の連結演算子として使用される。\n","40 \"foo\" & \"bar\" は \"foobar\" を返す。\n","41 また、主にマイクロソフト系では整数の十六進表記に &h を用い、&h0F (十進で15)のように表現する。\n","42 SGML、XML、HTMLでは、アンパサンドを使ってSGML実体を参照する。\n","43 \n","44 言語(げんご)は、狭義には「声による記号の体系」をいう。\n","45 広辞苑や大辞泉には次のように解説されている。\n","46 『日本大百科全書』では、「言語」という語は多義である、と解説され、大脳の言語中枢(英語版)に蓄えられた《語彙と文法規則の体系》を指すこともあり、その体系を用いる能力としてとらえることもある、と解説され、一方では、抽象的に「すべての人間が共有する言語能力」を指すこともあり、「個々の個別言語」を指すこともある、と解説されている。\n","47 広義の言語には、verbalなものとnon-verbalなもの(各種記号、アイコン、図形、ボディーランゲージ等)の両方を含み、日常のコミュニケーションでは狭義の言語表現に身振り、手振り、図示、擬音等も加えて表現されることもある。\n","48 言語は、人間が用いる意志伝達手段であり、社会集団内で形成習得され、意志を相互に伝達することや、抽象的な思考を可能にし、結果として人間の社会的活動や文化的活動を支えている。\n","49 言語には、文化の特徴が織り込まれており、共同体で用いられている言語の習得をすることによって、その共同体での社会的学習、および人格の形成をしていくことになる。\n"]}],"source":["# 訓練セットの内容を確認する\n","for i, text in enumerate(unsup_train_dataset[:50][\"text\"]):\n","    print(i, text)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17,"referenced_widgets":["35a049d621104307a7eb09e4cefc74ed","e6fe5e1347e245a782c224f7e66800d8","5b6602db0c854efa992981b9f8ca2292","4d385c0b26774e5a9919452f44296650","ea44fc237e8a4e4e96ad9fddf73387ce","a64a4334133a46278242abfc1dc2340c","0fefbf19a72a45de800237cbb3456978","a2addbc07ab74bf18a3ace0988c70453","32d794f43dde4fc19bc9b23144365905","f3549afac6ea4d3f8202d15a722d54dd","ce37271a61ca40b88e5790fdf9c672c2"]},"id":"hDkhqmfh2yOf","outputId":"6c4222fc-6c17-4651-8ae6-b909802c4ae3","tags":[]},"outputs":[{"output_type":"display_data","data":{"text/plain":["Filter:   0%|          | 0/24387500 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"35a049d621104307a7eb09e4cefc74ed"}},"metadata":{}}],"source":["# 訓練セットから空行の事例を除外する\n","unsup_train_dataset = unsup_train_dataset.filter(\n","    lambda example: example[\"text\"].strip() != \"\"\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17,"referenced_widgets":["7e2ca5bc8507424ba5dd941c3b835064","47c53f05e8f54b5ba52001a6d1a8a99f","f555988b42dd4df583ecc4d40726a8a4","dd432d4c9c0144548d9b244df3baf522","589e632a67714187b0eb54475d386f0e","7e37631d1b3e49f4944afebcc42ca848","c4f031fdcc914623834eb37f5a9100af","f5854e3530f7498cbe94393ed0737ade","ec1b8180a03a47d9a5192694de203e86","986b8ee5ce4d40068877b45c5c961771","fc02cdff8d7b40eaadea63bf2b8cabb2"]},"id":"LLyLOPCg2yOf","outputId":"8922c39e-0869-48ad-facd-bd8325971766","tags":[]},"outputs":[{"output_type":"display_data","data":{"text/plain":["Flattening the indices:   0%|          | 0/1000000 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e2ca5bc8507424ba5dd941c3b835064"}},"metadata":{}}],"source":["# 訓練セットをシャッフルし、最初の100万事例を取り出す\n","unsup_train_dataset = unsup_train_dataset.shuffle().select(\n","    range(1000000)\n",")\n","# パフォーマンスの低下を防ぐため、シャッフルされた状態の訓練セットを\n","# ディスクに書き込む\n","unsup_train_dataset = unsup_train_dataset.flatten_indices()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6NQlmnYZOZVJ","outputId":"b435c85f-0342-4368-8d54-7a297d70a3df","tags":[]},"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset({\n","    features: ['text'],\n","    num_rows: 1000000\n","})\n"]}],"source":["# 前処理後の訓練セットの形式と事例数を確認する\n","print(unsup_train_dataset)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DLHPkQGL2yOg","outputId":"76fd81f6-cc22-4a6d-e65f-8a3df39a2b6a","tags":[]},"outputs":[{"output_type":"stream","name":"stdout","text":["0 2005年の時点で、10,000人ものウズベキスタン人が韓国での労働に従事しており、その大部分が高麗人である。\n","1 小学5年生(11歳)の時から芸能活動を開始。\n","2 i ħ d d t | ψ ( t ) ⟩ = L ^ | ψ ( t ) ⟩ {\\displaystyle i\\hbar {\\frac {d}{dt}}|\\psi (t)\\rangle ={\\hat {L}}|\\psi (t)\\rangle }\n","3 安土宗論(あづちしゅうろん)は、1579年(天正7年)、安土城下の浄厳院で行われた浄土宗と法華宗の宗論。\n","4 1927年 オーストラリア選手権(1927ねんオーストラリアせんしゅけん、1927 Australian Championships)に関する記事。\n","5 さらにマップ上で最大8つまでしか建築できず(司令官アビリティの”解体”か設置したプレイヤー自らが出向いて解体する必要がある)\n","6 特に誉淳が1827年から作成した『古瓦譜』は畿内で600点以上の拓本を蒐集し、瓦当文様に着目したうえで編年を試みている。\n","7 マルクス主義者を広言し、メキシコ共産党の敵であり味方であった。\n","8 ICHILLIN'(アイチリン、朝: 아이칠린)は、韓国の7人組女性アイドルグループ。\n","9 マークVIは1983年にモデルサイクルを終了し、1984年のマークVII(英語版)はフルサイズセグメントから撤退し、マークシリーズは異なるセグメントに移行した。\n"]}],"source":["# 前処理後の訓練セットの内容を確認する\n","for i, text in enumerate(unsup_train_dataset[:10][\"text\"]):\n","    print(i, text)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":319,"referenced_widgets":["e4d6d3fd508a4f4c9bda98e27e7487bb","f9c362ebcfae4c6eb59f3a06a9cb1466","04d2cc4820ee40ba84dda04cc96c7868","bf2305f0f4144d13bc4cb0964ffe7838","01a9003e002c4c01a7f2a62368121b7d","f888daa161c54bd6b456594d5de9badf","f384d60046064680b21c22f6f712108b","fe9ba233c20942a99e93ff57478c2787","87953cfbab9f441c99221f269edbf843","617a3f8181aa406e8876b7a476ee4d20","d0d2b03503ef498b803362520283bbd0","70d649808c0c400198faebda5d523b37","dc0c0f6a18e3482880a55d31613e80e4","5cb5637bd70b4c6b802ebde09d508425","434b74dcdd5c4079b1bae7ceffaf382a","211857e54b774c8ab506b2860677045e","951a0abd60ee4a179ee9d54ba79662d5","f5a477e4af7d4e80b51029af98557dac","8ce95b4ef2504513810a50b7f4ed9ef1","b8b05e165e974957ad891e4ea53cf35a","ee3bc2f3275d4abb8c33b6fe7875635e","3fff44861f494fb296ee3be7a43a5278","1ef5312020db457db2e36f0fae6ebf0e","d5d23a2a3456480e8831f2bd609c4adb","4a40fd936b9e4648b03fc9625def4a5a","46f7c24436e043d2bbb440c280f90fb3","518a58e532f543f6bb55f00839acf59e","2c950601b67445e7a55713a64dbd407b","de5a9817de2140309bb2685fac0386b1","727f7f073d994241b5eb71790e4ab67f","b961973812b24676b90ddb223baa4f08","b67c38a3b2474b17aaed85d61df4910b","80b87fd43f7b41fea068814be686962c","027c3ce652ab4747bb4b7608146608b4","60e1e8c582004f8492b28f702c13cfe8","f118ffcfb0e0419a80548b054608f958","3e40f0a984b84488be319d4224d1ef96","9e1ecfb15b804db6b1fb2ed51395c3aa","157038cd7a8c44f5a5c2f53909ca90e6","af3a6473f2e245dc9ef8b7ad355df606","dcbda41fd704434aaf3fb49a57b3a604","726c937df7d24e8b9ea7b6f8bc098359","15d8948a9270449a917bc1e9a48a20e3","536e070c87674d25974697f5a16eaf16","94ae030f50b94e498d51cc3b53ba7e3c","76a56bb84231426984426a9706ede37f","397f40d732414ac3820991067664c300","9699dde85f61441fa298c04646b0fab8","a3159b3df85f4045954272a2d0a72d47","99f16feca9894bdb89b8769f2155b522","fa77984d21474c0188d5ee6fae100946","ce00df62fac742dc9d1d21f494579ec0","1a3ad6b087054cab921de231df73e1a2","7b14ab07940d4f0ca296640db1cc4af4","cd781c950c244addb2bd20ac56af15a7","d8f64e0f262c4bfa9a98895511f442b1","d4244defa7bd4f5dbe7de9f699dd84df","b905ed73479048308f8afff1497a6fb9","50ed0818c99146a396ac8d1277ebf168","b7f5ef2c96314974a82222e5d64931c2","1dc9033be06148bd80d9d9eae1c2e505","0fcd9e50a7b0407397178dd2d7cfa711","938bdaa1f9704a90a26cd5b8cdf737b2","f6779d83d8304f9c9f19c8067d5b3568","3f04f959792848e1b619bb1a68c244a5","6aaa4c5a322d49dea9d781af5cf8077e","459ed82144214907bc1acb5bc9be447f","a29a50d5dd3148cfbb59c1362e722750","ed6770be4ecd4666b972d0a785aa2a6b","8bbfa9cc305e48bca75e15ad3dfc80d2","38f1b8c89c9740e2b6ebd17c50a0114e","16ab5d26567445fa9b79917f8e2c4bd6","eb0b6707b15b44c7bf8d8d10b24fed02","37cfa673074b45cc91f70188eb859f55","e576ea59e2c04ff2af86d22a5abb8be1","4925b98e9e5246bbbef3591d5f9a3d52","9f0363b37d6841e2b1fb190bba340736","b3d8e850583c46649de1b2321767ef1e","8a73897a01df4e6789b6032b23a6855e","bf824834a16243499a6b09c670b557ab","b18a455a836f4eb6b3f7fcbb47e4aa90","83ef7d205a304849b24f16d0308fbe6d","47566cb424b149569920681097230432","cb4c2df7d16d42c6ad291e11a71c776a","2918d5e2f9d041468116dc881e56902e","afcb170e32cc42c5b3443437accbd7fc","fbf38527f9b04d64b3a65e9ec45f5a57","061b8bc94974496189362e1003126b11","44f872d955de4626a873759c9b9c01df","a2eaf294a479425f9b465ca50885324b","a52b7f74cb53434cb762777b7cfa44d8","40a9d7de3edf4903b94b6d35456da735","24352b8806644f868a947ee91ada70ad","10bea48069ea47b78cbb9c4e97e1c586","861bf4e471064ab182b653599085435e","cd60d049e18f4ed1a69e0f97a5818e7e","f12f9cd613c14f80b2813fe87fda19ad","c53838fa208743bf8de6224e076165ff","0d6e45ef16fe45649f72ce199ed55fc1"]},"id":"CabZESb62yOg","outputId":"be86f486-5f98-4a01-bad2-ed0244216cfb","tags":[]},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading builder script:   0%|          | 0.00/13.8k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e4d6d3fd508a4f4c9bda98e27e7487bb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading readme:   0%|          | 0.00/2.90k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"70d649808c0c400198faebda5d523b37"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading extra modules:   0%|          | 0.00/9.00k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ef5312020db457db2e36f0fae6ebf0e"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Downloading and preparing dataset jglue/JSTS to /root/.cache/huggingface/datasets/llm-book___jglue/JSTS/1.1.0/afed02e914319785e72f3ea981b4bd3e00089f2361b1137820c183c6b8173edd...\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"027c3ce652ab4747bb4b7608146608b4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading data:   0%|          | 0.00/653k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"94ae030f50b94e498d51cc3b53ba7e3c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading data:   0%|          | 0.00/84.2k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d8f64e0f262c4bfa9a98895511f442b1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"459ed82144214907bc1acb5bc9be447f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating train split: 0 examples [00:00, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b3d8e850583c46649de1b2321767ef1e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating validation split: 0 examples [00:00, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"44f872d955de4626a873759c9b9c01df"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Dataset jglue downloaded and prepared to /root/.cache/huggingface/datasets/llm-book___jglue/JSTS/1.1.0/afed02e914319785e72f3ea981b4bd3e00089f2361b1137820c183c6b8173edd. Subsequent calls will reuse this data.\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:datasets.builder:Found cached dataset jglue (/root/.cache/huggingface/datasets/llm-book___jglue/JSTS/1.1.0/afed02e914319785e72f3ea981b4bd3e00089f2361b1137820c183c6b8173edd)\n"]}],"source":["# Hugging Face Hubのllm-book/JGLUEのリポジトリから\n","# JSTSデータセットの訓練セットと検証セットを読み込み、\n","# それぞれをSimCSEの検証セットとテストセットとして使用する\n","valid_dataset = load_dataset(\n","    \"llm-book/JGLUE\", name=\"JSTS\", split=\"train\"\n",")\n","test_dataset = load_dataset(\n","    \"llm-book/JGLUE\", name=\"JSTS\", split=\"validation\"\n",")"]},{"cell_type":"markdown","metadata":{"id":"hRaIDkhXeGBR"},"source":["#### トークナイザと collate 関数の準備"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81,"referenced_widgets":["90b1baaa1ec24e0393a4867f76fa26f4","5a06f3e38ce24a7195ca6b672a86230f","db2d46a7e7ff48f7a11dce6f79a7c6cd","18a8881b7b724690a25e776e2d34866f","bd27f56948c74435884bd324980d46ff","c24f3c3f67344494af4ed6725ba601a7","96ef5ad216f64961b06501ac2cdeb236","28eb4ded376e474188edbe063178740e","ddf5e10001e44e5a8380477c0bbb7a14","1dbc993aa36b43c089c555d5c5b4c8fe","5181664f29914f7ea7deb1592278e45a","b3448196f322462b8f02099b08ca5604","40b4f8d32313422894558538b6440aa3","da5962b354b34a58bd168ba2fa2c6d17","44cc3f9c573a4b8a92fa4a25805b500e","2e677310ad854f8d891c40bc55f80f78","2104740880314e02a5286c4cef4d2f6f","6646eb127e034ab0bba22259adfc4cb3","7d2739d27c5b4290b45b64bdd26287c1","ba06574ca99f4b4896f69e70c0a9709e","53ebac681bf146d290fd521024de8fb9","1ebe7d3370214213909ceddd8c71b236"]},"id":"vExsdpU0eGBS","outputId":"64952091-1f21-4574-b36c-a83beddabb9e"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/251 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"90b1baaa1ec24e0393a4867f76fa26f4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/231k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b3448196f322462b8f02099b08ca5604"}},"metadata":{}}],"source":["from transformers import AutoTokenizer\n","\n","# Hugging Face Hubにおけるモデル名を指定する\n","base_model_name = \"cl-tohoku/bert-base-japanese-v3\"\n","# モデル名からトークナイザを初期化する\n","tokenizer = AutoTokenizer.from_pretrained(base_model_name)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BRVoHfpQeGBS"},"outputs":[],"source":["import torch\n","from torch import Tensor\n","from transformers import BatchEncoding\n","\n","def unsup_train_collate_fn(\n","    examples: list[dict],\n",") -> dict[str, BatchEncoding | Tensor]:\n","    \"\"\"教師なしSimCSEの訓練セットのミニバッチを作成\"\"\"\n","    # ミニバッチに含まれる文にトークナイザを適用する\n","    tokenized_texts = tokenizer(\n","        [example[\"text\"] for example in examples],\n","        padding=True,\n","        truncation=True,\n","        max_length=32,\n","        return_tensors=\"pt\",\n","    )\n","\n","    # 文と文の類似度行列における正例ペアの位置を示すTensorを作成する\n","    # 行列のi行目の事例（文）に対してi列目の事例（文）との組が正例ペアとなる\n","    labels = torch.arange(len(examples))\n","\n","    return {\n","        \"tokenized_texts_1\": tokenized_texts,\n","        \"tokenized_texts_2\": tokenized_texts,\n","        \"labels\": labels,\n","    }"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A0HWUrbReGBT"},"outputs":[],"source":["def eval_collate_fn(\n","    examples: list[dict],\n",") -> dict[str, BatchEncoding | Tensor]:\n","    \"\"\"SimCSEの検証・テストセットのミニバッチを作成\"\"\"\n","    # ミニバッチの文ペアに含まれる文（文1と文2）のそれぞれに\n","    # トークナイザを適用する\n","    tokenized_texts_1 = tokenizer(\n","        [example[\"sentence1\"] for example in examples],\n","        padding=True,\n","        truncation=True,\n","        max_length=512,\n","        return_tensors=\"pt\",\n","    )\n","    tokenized_texts_2 = tokenizer(\n","        [example[\"sentence2\"] for example in examples],\n","        padding=True,\n","        truncation=True,\n","        max_length=512,\n","        return_tensors=\"pt\",\n","    )\n","\n","    # 文1と文2の類似度行列における正例ペアの位置を示すTensorを作成する\n","    # 行列のi行目の事例（文1）に対して\n","    # i列目の事例（文2）との組が正例ペアとなる\n","    labels = torch.arange(len(examples))\n","\n","    # データセットに付与された類似度スコアのTensorを作成する\n","    label_scores = torch.tensor(\n","        [example[\"label\"] for example in examples]\n","    )\n","\n","    return {\n","        \"tokenized_texts_1\": tokenized_texts_1,\n","        \"tokenized_texts_2\": tokenized_texts_2,\n","        \"labels\": labels,\n","        \"label_scores\": label_scores,\n","    }"]},{"cell_type":"markdown","metadata":{"id":"B7Mx_JgbeGBT"},"source":["#### モデルの準備"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3XViMIiLeGBT","colab":{"base_uri":"https://localhost:8080/","height":159,"referenced_widgets":["5f5894193c0b477e8e167072b7ab2ced","4e089ac6ea004c65bc6e25729a5d0ced","4bd07f03390e4719bd18d87241b0a2cd","db036b658ea14d95925ed6c5b614380e","6d6d5fb9d4d14b129eb88e806333e905","02ac061c03204ffea207679d5f956961","e084ccc1c58043e2be1ef9030fdaacb8","35a8af1dae2c455284548cc99f73e7b9","cd641683a7f448c580271d8c93208d80","f64f667ab9bc47718b5eb80606656f07","edea1fe293ee42e5833c88f87392529b","72e0db7b89a745389a67b05c0a77a643","8d15dfe8e0794fdfbf7dd1e3f32cbfda","0cf89b115aee48ec880220d6ff12c28c","ae047d0656bf4eaa8e5ceb9eb73d2b9a","febbac57cd0a463fbadd1c33589fe6ab","408a2c75bddc470f8fccb223e976d5d4","1a6ea0d2df6c4061902531a651a409ad","56fc7d14815e47adba68ced07e3377e4","c9a3f96659d24e72ab776d55824f55a4","02a50be6e1834d99b35a3b2776102e35","756d23b53ae9460db7ebcc1b692051b8"]},"outputId":"66208901-1364-4473-824b-ed35ad56ec15"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/472 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f5894193c0b477e8e167072b7ab2ced"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/447M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"72e0db7b89a745389a67b05c0a77a643"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at cl-tohoku/bert-base-japanese-v3 were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}],"source":["import torch.nn as nn\n","import torch.nn.functional as F\n","from transformers import AutoModel\n","from transformers.utils import ModelOutput\n","\n","class SimCSEModel(nn.Module):\n","    \"\"\"SimCSEのモデル\"\"\"\n","\n","    def __init__(\n","        self,\n","        base_model_name: str,\n","        mlp_only_train: bool = False,\n","        temperature: float = 0.05,\n","    ):\n","        \"\"\"モデルの初期化\"\"\"\n","        super().__init__()\n","\n","        # モデル名からエンコーダを初期化する\n","        self.encoder = AutoModel.from_pretrained(base_model_name)\n","        # パラメータをメモリ上に隣接した形で配置\n","        # これを実行しない場合、モデルの保存でエラーになることがある\n","        for param in self.encoder.parameters():\n","            param.data = param.data.contiguous()\n","        # MLP層の次元数\n","        self.hidden_size = self.encoder.config.hidden_size\n","        # MLP層の線形層\n","        self.dense = nn.Linear(self.hidden_size, self.hidden_size)\n","        # MLP層の活性化関数\n","        self.activation = nn.Tanh()\n","\n","        # MLP層による変換を訓練時にのみ適用するよう設定するフラグ\n","        self.mlp_only_train = mlp_only_train\n","        # 交差エントロピー損失の計算時に使用する温度\n","        self.temperature = temperature\n","\n","    def encode_texts(self, tokenized_texts: BatchEncoding) -> Tensor:\n","        \"\"\"エンコーダを用いて文をベクトルに変換\"\"\"\n","        # トークナイズされた文をエンコーダに入力する\n","        encoded_texts = self.encoder(**tokenized_texts)\n","        # モデルの最終層の出力（last_hidden_state）の\n","        # [CLS]トークン（0番目の位置のトークン）のベクトルを取り出す\n","        encoded_texts = encoded_texts.last_hidden_state[:, 0]\n","\n","        # self.mlp_only_trainのフラグがTrueに設定されていて\n","        # かつ訓練時でない場合、MLP層の変換を適用せずにベクトルを返す\n","        if self.mlp_only_train and not self.training:\n","            return encoded_texts\n","\n","        # MLP層によるベクトルの変換を行う\n","        encoded_texts = self.dense(encoded_texts)\n","        encoded_texts = self.activation(encoded_texts)\n","\n","        return encoded_texts\n","\n","    def forward(\n","        self,\n","        tokenized_texts_1: BatchEncoding,\n","        tokenized_texts_2: BatchEncoding,\n","        labels: Tensor,\n","        label_scores: Tensor | None = None,\n","    ) -> ModelOutput:\n","        \"\"\"モデルの前向き計算を定義\"\"\"\n","        # 文ペアをベクトルに変換する\n","        encoded_texts_1 = self.encode_texts(tokenized_texts_1)\n","        encoded_texts_2 = self.encode_texts(tokenized_texts_2)\n","\n","        # 文ペアの類似度行列を作成する\n","        sim_matrix = F.cosine_similarity(\n","            encoded_texts_1.unsqueeze(1),\n","            encoded_texts_2.unsqueeze(0),\n","            dim=2,\n","        )\n","\n","        # 交差エントロピー損失を求める\n","        loss = F.cross_entropy(sim_matrix / self.temperature, labels)\n","\n","        # 性能評価に使用するため、正例ペアに対するスコアを類似度行列から取り出す\n","        positive_mask = F.one_hot(labels, sim_matrix.size(1)).bool()\n","        positive_scores = torch.masked_select(\n","            sim_matrix, positive_mask\n","        )\n","\n","        return ModelOutput(loss=loss, scores=positive_scores)\n","\n","# 教師なしSimCSEのモデルを初期化する\n","unsup_model = SimCSEModel(base_model_name, mlp_only_train=True)"]},{"cell_type":"markdown","metadata":{"id":"b7f9jbBUeGBU"},"source":["#### `Trainer` の準備"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_e_VPrjmeGBU"},"outputs":[],"source":["from scipy.stats import spearmanr\n","from transformers import EvalPrediction\n","\n","def compute_metrics(p: EvalPrediction) -> dict[str, float]:\n","    \"\"\"\n","    モデルが予測したスコアと評価用データのスコアの\n","    スピアマンの順位相関係数を計算\n","    \"\"\"\n","    scores = p.predictions\n","    labels, label_scores = p.label_ids\n","\n","    spearman = spearmanr(scores, label_scores).statistic\n","\n","    return {\"spearman\": spearman}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tagJMAMFeGBU"},"outputs":[],"source":["from transformers import TrainingArguments\n","\n","# 教師なしSimCSEの訓練のハイパーパラメータを設定する\n","unsup_training_args = TrainingArguments(\n","    output_dir=\"outputs_unsup_simcse\",  # 結果の保存先フォルダ\n","    per_device_train_batch_size=64,  # 訓練時のバッチサイズ\n","    per_device_eval_batch_size=64,  # 評価時のバッチサイズ\n","    learning_rate=3e-5,  # 学習率\n","    num_train_epochs=1,  # 訓練エポック数\n","    evaluation_strategy=\"steps\",  # 検証セットによる評価のタイミング\n","    eval_steps=250,  # 検証セットによる評価を行う訓練ステップ数の間隔\n","    logging_steps=250,  # ロギングを行う訓練ステップ数の間隔\n","    save_steps=250,  # チェックポイントを保存する訓練ステップ数の間隔\n","    save_total_limit=1,  # 保存するチェックポイントの最大数\n","    fp16=True,  # 自動混合精度演算の有効化\n","    load_best_model_at_end=True,  # 最良のモデルを訓練終了後に読み込むか\n","    metric_for_best_model=\"spearman\",  # 最良のモデルを決定する評価指標\n","    remove_unused_columns=False,  # データセットの不要フィールドを削除するか\n","    report_to=\"none\",  # 外部ツールへのログを無効化\n",")"]},{"cell_type":"code","source":["from datasets import Dataset\n","from torch.utils.data import DataLoader\n","from transformers import Trainer\n","\n","class SimCSETrainer(Trainer):\n","    \"\"\"SimCSEの訓練に使用するTrainer\"\"\"\n","\n","    def get_eval_dataloader(\n","        self, eval_dataset: Dataset | None = None\n","    ) -> DataLoader:\n","        \"\"\"\n","        検証・テストセットのDataLoaderでeval_collate_fnを使うように\n","        Trainerのget_eval_dataloaderをオーバーライド\n","        \"\"\"\n","        if eval_dataset is None:\n","            eval_dataset = self.eval_dataset\n","\n","        return DataLoader(\n","            eval_dataset,\n","            batch_size=64,\n","            collate_fn=eval_collate_fn,\n","            pin_memory=True,\n","        )\n","\n","# 教師なしSimCSEのTrainerを初期化する\n","unsup_trainer = SimCSETrainer(\n","    model=unsup_model,\n","    args=unsup_training_args,\n","    data_collator=unsup_train_collate_fn,\n","    train_dataset=unsup_train_dataset,\n","    eval_dataset=valid_dataset,\n","    compute_metrics=compute_metrics,\n",")"],"metadata":{"id":"QpXHhKR3qH1M"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"T5GgD6P-eGBV"},"source":["#### 訓練の実行"]},{"cell_type":"code","source":["# 教師なしSimCSEの訓練を行う\n","unsup_trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"B2EAkj0_bHFE","outputId":"16df5d31-c112-4f06-8466-ee50665f7279"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='15625' max='15625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [15625/15625 1:28:06, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Spearman</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>250</td>\n","      <td>0.002000</td>\n","      <td>2.657105</td>\n","      <td>0.690523</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.000400</td>\n","      <td>2.568554</td>\n","      <td>0.692600</td>\n","    </tr>\n","    <tr>\n","      <td>750</td>\n","      <td>0.000100</td>\n","      <td>2.461003</td>\n","      <td>0.716650</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.000700</td>\n","      <td>2.443940</td>\n","      <td>0.722778</td>\n","    </tr>\n","    <tr>\n","      <td>1250</td>\n","      <td>0.000200</td>\n","      <td>2.412055</td>\n","      <td>0.728994</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>0.000100</td>\n","      <td>2.407356</td>\n","      <td>0.730363</td>\n","    </tr>\n","    <tr>\n","      <td>1750</td>\n","      <td>0.000100</td>\n","      <td>2.337075</td>\n","      <td>0.737031</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>0.000100</td>\n","      <td>2.342816</td>\n","      <td>0.736433</td>\n","    </tr>\n","    <tr>\n","      <td>2250</td>\n","      <td>0.000000</td>\n","      <td>2.321053</td>\n","      <td>0.744957</td>\n","    </tr>\n","    <tr>\n","      <td>2500</td>\n","      <td>0.000300</td>\n","      <td>2.343930</td>\n","      <td>0.737874</td>\n","    </tr>\n","    <tr>\n","      <td>2750</td>\n","      <td>0.000000</td>\n","      <td>2.319731</td>\n","      <td>0.745333</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>0.000400</td>\n","      <td>2.286810</td>\n","      <td>0.752455</td>\n","    </tr>\n","    <tr>\n","      <td>3250</td>\n","      <td>0.000100</td>\n","      <td>2.266464</td>\n","      <td>0.753584</td>\n","    </tr>\n","    <tr>\n","      <td>3500</td>\n","      <td>0.000000</td>\n","      <td>2.285644</td>\n","      <td>0.752092</td>\n","    </tr>\n","    <tr>\n","      <td>3750</td>\n","      <td>0.000000</td>\n","      <td>2.274388</td>\n","      <td>0.754367</td>\n","    </tr>\n","    <tr>\n","      <td>4000</td>\n","      <td>0.000000</td>\n","      <td>2.257628</td>\n","      <td>0.758936</td>\n","    </tr>\n","    <tr>\n","      <td>4250</td>\n","      <td>0.000000</td>\n","      <td>2.255583</td>\n","      <td>0.760148</td>\n","    </tr>\n","    <tr>\n","      <td>4500</td>\n","      <td>0.000000</td>\n","      <td>2.247395</td>\n","      <td>0.762292</td>\n","    </tr>\n","    <tr>\n","      <td>4750</td>\n","      <td>0.000100</td>\n","      <td>2.270459</td>\n","      <td>0.753907</td>\n","    </tr>\n","    <tr>\n","      <td>5000</td>\n","      <td>0.000200</td>\n","      <td>2.340728</td>\n","      <td>0.751089</td>\n","    </tr>\n","    <tr>\n","      <td>5250</td>\n","      <td>0.000100</td>\n","      <td>2.322395</td>\n","      <td>0.755703</td>\n","    </tr>\n","    <tr>\n","      <td>5500</td>\n","      <td>0.000300</td>\n","      <td>2.330641</td>\n","      <td>0.748381</td>\n","    </tr>\n","    <tr>\n","      <td>5750</td>\n","      <td>0.000000</td>\n","      <td>2.381598</td>\n","      <td>0.745563</td>\n","    </tr>\n","    <tr>\n","      <td>6000</td>\n","      <td>0.000200</td>\n","      <td>2.409234</td>\n","      <td>0.739738</td>\n","    </tr>\n","    <tr>\n","      <td>6250</td>\n","      <td>0.000100</td>\n","      <td>2.383834</td>\n","      <td>0.744940</td>\n","    </tr>\n","    <tr>\n","      <td>6500</td>\n","      <td>0.000200</td>\n","      <td>2.378203</td>\n","      <td>0.746439</td>\n","    </tr>\n","    <tr>\n","      <td>6750</td>\n","      <td>0.000100</td>\n","      <td>2.372593</td>\n","      <td>0.747922</td>\n","    </tr>\n","    <tr>\n","      <td>7000</td>\n","      <td>0.000200</td>\n","      <td>2.369230</td>\n","      <td>0.751055</td>\n","    </tr>\n","    <tr>\n","      <td>7250</td>\n","      <td>0.000000</td>\n","      <td>2.369647</td>\n","      <td>0.751082</td>\n","    </tr>\n","    <tr>\n","      <td>7500</td>\n","      <td>0.000100</td>\n","      <td>2.366100</td>\n","      <td>0.750837</td>\n","    </tr>\n","    <tr>\n","      <td>7750</td>\n","      <td>0.000000</td>\n","      <td>2.361833</td>\n","      <td>0.751714</td>\n","    </tr>\n","    <tr>\n","      <td>8000</td>\n","      <td>0.000100</td>\n","      <td>2.334600</td>\n","      <td>0.752134</td>\n","    </tr>\n","    <tr>\n","      <td>8250</td>\n","      <td>0.000000</td>\n","      <td>2.341602</td>\n","      <td>0.752597</td>\n","    </tr>\n","    <tr>\n","      <td>8500</td>\n","      <td>0.000000</td>\n","      <td>2.336557</td>\n","      <td>0.753802</td>\n","    </tr>\n","    <tr>\n","      <td>8750</td>\n","      <td>0.000000</td>\n","      <td>2.336756</td>\n","      <td>0.753631</td>\n","    </tr>\n","    <tr>\n","      <td>9000</td>\n","      <td>0.000000</td>\n","      <td>2.337389</td>\n","      <td>0.752959</td>\n","    </tr>\n","    <tr>\n","      <td>9250</td>\n","      <td>0.000000</td>\n","      <td>2.336196</td>\n","      <td>0.751984</td>\n","    </tr>\n","    <tr>\n","      <td>9500</td>\n","      <td>0.000000</td>\n","      <td>2.340319</td>\n","      <td>0.750568</td>\n","    </tr>\n","    <tr>\n","      <td>9750</td>\n","      <td>0.000100</td>\n","      <td>2.345603</td>\n","      <td>0.750183</td>\n","    </tr>\n","    <tr>\n","      <td>10000</td>\n","      <td>0.000100</td>\n","      <td>2.340587</td>\n","      <td>0.750829</td>\n","    </tr>\n","    <tr>\n","      <td>10250</td>\n","      <td>0.000000</td>\n","      <td>2.333943</td>\n","      <td>0.751075</td>\n","    </tr>\n","    <tr>\n","      <td>10500</td>\n","      <td>0.000000</td>\n","      <td>2.328826</td>\n","      <td>0.751606</td>\n","    </tr>\n","    <tr>\n","      <td>10750</td>\n","      <td>0.000100</td>\n","      <td>2.355002</td>\n","      <td>0.741079</td>\n","    </tr>\n","    <tr>\n","      <td>11000</td>\n","      <td>0.000000</td>\n","      <td>2.358025</td>\n","      <td>0.742249</td>\n","    </tr>\n","    <tr>\n","      <td>11250</td>\n","      <td>0.000000</td>\n","      <td>2.361308</td>\n","      <td>0.741376</td>\n","    </tr>\n","    <tr>\n","      <td>11500</td>\n","      <td>0.000000</td>\n","      <td>2.357748</td>\n","      <td>0.742467</td>\n","    </tr>\n","    <tr>\n","      <td>11750</td>\n","      <td>0.000100</td>\n","      <td>2.355950</td>\n","      <td>0.742925</td>\n","    </tr>\n","    <tr>\n","      <td>12000</td>\n","      <td>0.000000</td>\n","      <td>2.344626</td>\n","      <td>0.745823</td>\n","    </tr>\n","    <tr>\n","      <td>12250</td>\n","      <td>0.000100</td>\n","      <td>2.364207</td>\n","      <td>0.739172</td>\n","    </tr>\n","    <tr>\n","      <td>12500</td>\n","      <td>0.000100</td>\n","      <td>2.339099</td>\n","      <td>0.744804</td>\n","    </tr>\n","    <tr>\n","      <td>12750</td>\n","      <td>0.000100</td>\n","      <td>2.351532</td>\n","      <td>0.743268</td>\n","    </tr>\n","    <tr>\n","      <td>13000</td>\n","      <td>0.000100</td>\n","      <td>2.343686</td>\n","      <td>0.746080</td>\n","    </tr>\n","    <tr>\n","      <td>13250</td>\n","      <td>0.000000</td>\n","      <td>2.345328</td>\n","      <td>0.746378</td>\n","    </tr>\n","    <tr>\n","      <td>13500</td>\n","      <td>0.000000</td>\n","      <td>2.344684</td>\n","      <td>0.746823</td>\n","    </tr>\n","    <tr>\n","      <td>13750</td>\n","      <td>0.000200</td>\n","      <td>2.342316</td>\n","      <td>0.747280</td>\n","    </tr>\n","    <tr>\n","      <td>14000</td>\n","      <td>0.000100</td>\n","      <td>2.342435</td>\n","      <td>0.747336</td>\n","    </tr>\n","    <tr>\n","      <td>14250</td>\n","      <td>0.000000</td>\n","      <td>2.346266</td>\n","      <td>0.745912</td>\n","    </tr>\n","    <tr>\n","      <td>14500</td>\n","      <td>0.000000</td>\n","      <td>2.345729</td>\n","      <td>0.745930</td>\n","    </tr>\n","    <tr>\n","      <td>14750</td>\n","      <td>0.000000</td>\n","      <td>2.345170</td>\n","      <td>0.745870</td>\n","    </tr>\n","    <tr>\n","      <td>15000</td>\n","      <td>0.000000</td>\n","      <td>2.343824</td>\n","      <td>0.746205</td>\n","    </tr>\n","    <tr>\n","      <td>15250</td>\n","      <td>0.000000</td>\n","      <td>2.344468</td>\n","      <td>0.746079</td>\n","    </tr>\n","    <tr>\n","      <td>15500</td>\n","      <td>0.000000</td>\n","      <td>2.343429</td>\n","      <td>0.746261</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=15625, training_loss=0.0001253565512150526, metrics={'train_runtime': 5290.4647, 'train_samples_per_second': 189.019, 'train_steps_per_second': 2.953, 'total_flos': 0.0, 'train_loss': 0.0001253565512150526, 'epoch': 1.0})"]},"metadata":{},"execution_count":18}]},{"cell_type":"markdown","metadata":{"id":"nzUDSMJQeGBV"},"source":["#### 性能評価"]},{"cell_type":"code","source":["# 検証セットで教師なしSimCSEのモデルの評価を行う\n","unsup_trainer.evaluate(valid_dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":154},"id":"arHD0j0xxLLT","outputId":"d9f24b50-e2d9-458b-a9ae-82d523e447e9"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='195' max='195' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [195/195 00:16]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["{'eval_loss': 2.2473950386047363,\n"," 'eval_spearman': 0.7622917049018967,\n"," 'eval_runtime': 16.8507,\n"," 'eval_samples_per_second': 738.902,\n"," 'eval_steps_per_second': 11.572,\n"," 'epoch': 1.0}"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["# テストセットで教師なしSimCSEのモデルの評価を行う\n","unsup_trainer.evaluate(test_dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":154},"id":"TKP5Jk8EhBQq","outputId":"3dfb1a7d-cec9-4ba9-d80b-d51aa86a282f"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='218' max='195' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [195/195 00:18]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["{'eval_loss': 2.1452813148498535,\n"," 'eval_spearman': 0.8034015311347286,\n"," 'eval_runtime': 2.0193,\n"," 'eval_samples_per_second': 721.531,\n"," 'eval_steps_per_second': 11.39,\n"," 'epoch': 1.0}"]},"metadata":{},"execution_count":20}]},{"cell_type":"markdown","source":["#### トークナイザとモデルの保存"],"metadata":{"id":"AH6muFERWbco"}},{"cell_type":"code","source":["# 教師なしSimCSEのエンコーダを保存\n","encoder_path = \"outputs_unsup_simcse/encoder\"\n","unsup_model.encoder.save_pretrained(encoder_path)\n","tokenizer.save_pretrained(encoder_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CpytBpIZWeYD","outputId":"9e5c5c06-6f6e-4389-b44f-4402b34f7c3e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["('outputs_unsup_simcse/encoder/tokenizer_config.json',\n"," 'outputs_unsup_simcse/encoder/special_tokens_map.json',\n"," 'outputs_unsup_simcse/encoder/vocab.txt',\n"," 'outputs_unsup_simcse/encoder/added_tokens.json')"]},"metadata":{},"execution_count":21}]},{"cell_type":"markdown","metadata":{"id":"8qUnaT91uhqm"},"source":["#### Google ドライブへの保存"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lJU67CyRumcu","colab":{"base_uri":"https://localhost:8080/"},"outputId":"c7e2ccda-f49c-460c-f64e-c97b27a20aac"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at drive\n"]}],"source":["from google.colab import drive\n","\n","# Googleドライブをマウントする\n","drive.mount(\"drive\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7pv7f0f0uzaV"},"outputs":[],"source":["# 保存されたモデルをGoogleドライブのフォルダにコピーする\n","!mkdir -p drive/MyDrive/llm-book\n","!cp -r outputs_unsup_simcse drive/MyDrive/llm-book"]},{"cell_type":"markdown","source":["### 8.3.2 教師あり SimCSE の実装"],"metadata":{"id":"71zPcoD8X-n3"}},{"cell_type":"markdown","metadata":{"id":"Pt5b9EfTBWsB"},"source":["#### 準備"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"id":"D8WGpkgQYGXm"},"outputs":[],"source":["# 乱数のシードを設定する\n","set_seed(42)"]},{"cell_type":"markdown","metadata":{"id":"Lpag4rbreGBc"},"source":["#### データセットの読み込みと前処理"]},{"cell_type":"code","source":["# Hugging Face Hubのllm-book/jsnliのリポジトリから\n","# JSNLIの訓練セットを読み込む\n","jsnli_dataset = load_dataset(\"llm-book/jsnli\", split=\"train\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":172,"referenced_widgets":["5c0510e87d3445aeb0ba0218f3a55ab6","0832679233b34cfd80472945aa810fe0","bd1629e2e7c9456a806ad348fa54fd73","3f429290d97a479aaf989ed3745a459a","0fc567da4b3c4860a1ffd13378c80728","5c7cc6e1350344e9a92001f19980ebdf","c1f5b992af714d92ba018ac1905176a3","bae7923ed883403aa49862419c4cf6df","0cf255e26deb4f5ca805441ab71f9315","25e56cb3b4ea4e0c8a7ea9941c89ed6b","79d398a8aa274564b8d59e36af18de89","159ebcab56de4d9eb6bf881567896e90","8a52186cc87141dbaf748680d7e2729a","360e3b14405b4a0b9fc1a2a028b08b59","3f53b9992d634f078edff7503c6f0995","cd604eb06ae1491784541e35c83efde1","1ad9ffac7ee4484f86e3afb86b371960","13aafca3c4a54510864bd5645c832ff6","ba3f3ea355f648eab62263491a2cb698","639c30505eaa4f26bf8132d9762b3e83","ec962321659147f1b11ddc6bde00d79a","2e67ed8463eb482a8108cec10bc0ebf9","61cfbc67b99d4e8fa180c3a3204997db","7b22603750b44986a442f366549e05e5","f92ff2dd75d643b98d4999ae5dc26ea7","f0af29f7372f47f5ba46693b94c682d0","2ead3b187fc84b538b7e6bb9514076b6","41f53c3f91894efc829f518c9ce4809e","c260f3b7fb4d48ad82a25c7c94bc6840","972dadecaa094b29a58adb0b75d1da11","5dbce2eb697e4028ac4bacb6baa8593d","b175f92e311e44ceb984e6eb57bea7a9","fb0489210d6f4f15897d805777dd5f2b","653783c1732745329927826cdc2b5c79","12ee0537ebe040e385478235402af81c","020d5773b92d4ed89aeb2228dff8b9dd","247da7ad05574002a24123893ef3f008","905d0abe748d4cc3b63c41cab43cadb4","1c058a76df9e44838e883b0d90996f7b","595aa965bed945dab1d048f49464b56e","98932c6b15ea470a9abaf9b681adc0b9","4d8a17c433794a52adcae09170ee088c","b398bb9bcdc142139de6ac87ac4f9abe","947d8981c1cb40fa96d941a01762046d","859bc801a3854aa7a8613806141221e5","78bd5cf864764b87af72ef8eb9aba5de","f9667f1ef67b438fa50ed45e0e4f47c5","342c309ea782470b94cdeb84d065c449","f98a0a0040df438f87ba141bade021b4","f02d6c384d654c5d84ccd7e78e8e3c78","fb9d81e22f1b4861bd8a862d50d3f4b8","40d7103caf0b423f9862c03672bc541e","8c4ca0bb544745cabcf2fff4cb61b9d2","5453e17596df403eb0b7f7de076667b6","bca30607442647498c903129f0a12ae8"]},"id":"pVD-zU4nIhsG","outputId":"df11a626-eac6-4f7a-d870-458fcbccf192"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading builder script:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c0510e87d3445aeb0ba0218f3a55ab6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading readme:   0%|          | 0.00/802 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"159ebcab56de4d9eb6bf881567896e90"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Downloading and preparing dataset jsnli/default to /root/.cache/huggingface/datasets/llm-book___jsnli/default/1.0.0/0f9249bf69fb74d71f6adee2069ada127288c4ab94cc1a91c0b0628f754893fe...\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading data:   0%|          | 0.00/44.9M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"61cfbc67b99d4e8fa180c3a3204997db"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating train split:   0%|          | 0/533005 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"653783c1732745329927826cdc2b5c79"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating validation split:   0%|          | 0/3916 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"859bc801a3854aa7a8613806141221e5"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Dataset jsnli downloaded and prepared to /root/.cache/huggingface/datasets/llm-book___jsnli/default/1.0.0/0f9249bf69fb74d71f6adee2069ada127288c4ab94cc1a91c0b0628f754893fe. Subsequent calls will reuse this data.\n"]}]},{"cell_type":"code","source":["# JSNLIの訓練セットの形式と事例数を確認する\n","print(jsnli_dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g2I2kKaRTz2e","outputId":"5b2cc42d-0d44-4a13-fa5c-a0998d906d58"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset({\n","    features: ['premise', 'hypothesis', 'label'],\n","    num_rows: 533005\n","})\n"]}]},{"cell_type":"code","source":["from pprint import pprint\n","\n","# JSNLIの訓練セットの内容を確認する\n","pprint(jsnli_dataset[0])\n","pprint(jsnli_dataset[1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N1VMpsPdT3mU","outputId":"bc71d5c6-edb0-462c-adc5-0d7c564110b9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'hypothesis': '男 は 魔法 の ショー の ため に ナイフ を 投げる 行為 を 練習 して い ます 。',\n"," 'label': 'neutral',\n"," 'premise': 'ガレージ で 、 壁 に ナイフ を 投げる 男 。'}\n","{'hypothesis': '女性 が 畑 で 踊って い ます 。',\n"," 'label': 'contradiction',\n"," 'premise': '茶色 の ドレス を 着た 女性 が ベンチ に 座って い ます 。'}\n"]}]},{"cell_type":"code","source":["import csv\n","import random\n","from typing import Iterator\n","\n","# JSNLIの訓練セットから、前提文とラベルごとに仮説文をまとめたdictを作成する\n","premise2hypotheses = {}\n","\n","premises = jsnli_dataset[\"premise\"]  # 前提文\n","hypotheses = jsnli_dataset[\"hypothesis\"]  # 仮説文\n","labels = jsnli_dataset[\"label\"]  # ラベル\n","\n","for premise, hypothesis, label in zip(premises, hypotheses, labels):\n","    if premise not in premise2hypotheses:\n","        premise2hypotheses[premise] = {\n","            \"entailment\": [],\n","            \"neutral\": [],\n","            \"contradiction\": [],\n","        }\n","\n","    premise2hypotheses[premise][label].append(hypothesis)"],"metadata":{"id":"YZX6AxqwNqWI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def generate_sup_train_example() -> Iterator[dict[str, str]]:\n","    \"\"\"教師ありSimCSEの訓練セットの事例を生成\"\"\"\n","    # JSNLIのデータから (前提文,「含意」ラベルの仮説文,「矛盾」ラベルの仮説文)\n","    # の三つ組を生成する\n","    for premise, hypotheses in premise2hypotheses.items():\n","        # 「矛盾」ラベルの仮説文が一つもない事例はスキップする\n","        if len(hypotheses[\"contradiction\"]) == 0:\n","            continue\n","\n","        # 「含意」ラベルの仮説文一つにつき、「矛盾」ラベルの仮説文一つを\n","        # ランダムに関連付ける\n","        for entailment_hypothesis in hypotheses[\"entailment\"]:\n","            contradiction_hypothesis = random.choice(\n","                hypotheses[\"contradiction\"]\n","            )\n","            # (前提文,「含意」ラベルの仮説文,「矛盾」ラベルの仮説文) の三つ組を\n","            # dictとして生成する\n","            yield {\n","                \"premise\": premise,\n","                \"entailment_hypothesis\": entailment_hypothesis,\n","                \"contradiction_hypothesis\": contradiction_hypothesis,\n","            }\n","\n","# 定義したジェネレータ関数を用いて、教師ありSimCSEの訓練セットを構築する\n","sup_train_dataset = Dataset.from_generator(generate_sup_train_example)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":56,"referenced_widgets":["1e4de3af609a4ecf8d5b7355af2ca655","227fe6625ea54c93bae1264b94648c77","6c3b1bef33ca48c98404517511a421e7","1fffdcf94c7b4a30bab8bc036d075a8e","2ff1192d08ff45e3b85a6c59b357e216","a5d3cce33997403b8821cd9bdb2d1d14","77699ba6ac5e4cef8166882a7bdb54d6","594417a289e9463595df4184405c6501","cab78c4d54344382ba020a46adbedca7","b698800dc6ad4bd5b66cabb8a8042dcb","65e8f85e57ea4cffa78a92a73d3a3ee1"]},"id":"6LKSO-z2US8m","outputId":"7427d7c6-ced8-4021-e5e6-c5b01c84d348"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading and preparing dataset generator/default to /root/.cache/huggingface/datasets/generator/default-d1c3ccc1c7d00cd2/0.0.0...\n"]},{"output_type":"display_data","data":{"text/plain":["Generating train split: 0 examples [00:00, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e4de3af609a4ecf8d5b7355af2ca655"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Dataset generator downloaded and prepared to /root/.cache/huggingface/datasets/generator/default-d1c3ccc1c7d00cd2/0.0.0. Subsequent calls will reuse this data.\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k_92_vKbeGBd","outputId":"1540ea98-411e-43a7-9c00-fdaa7fa50a14"},"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset({\n","    features: ['premise', 'entailment_hypothesis', 'contradiction_hypothesis'],\n","    num_rows: 173438\n","})\n"]}],"source":["# 訓練セットの形式と事例数を確認する\n","print(sup_train_dataset)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C0gg970beGBd","outputId":"d94eab94-9825-4565-a17c-6d498dd86a67"},"outputs":[{"output_type":"stream","name":"stdout","text":["{'contradiction_hypothesis': '男 が 台所 の テーブル で 本 を 読んで い ます 。',\n"," 'entailment_hypothesis': 'ガレージ に 男 が い ます 。',\n"," 'premise': 'ガレージ で 、 壁 に ナイフ を 投げる 男 。'}\n","{'contradiction_hypothesis': '黒人 は デスクトップ コンピューター を 使用 し ます 。',\n"," 'entailment_hypothesis': '人 は 椅子 に 座って い ます 。',\n"," 'premise': 'ラップ トップ コンピューター を 使用 して 机 に 座って いる 若い 白人 男 。'}\n"]}],"source":["# 訓練セットの内容を確認する\n","pprint(sup_train_dataset[0])\n","pprint(sup_train_dataset[1])"]},{"cell_type":"markdown","metadata":{"id":"nwgmBGrQeGBd"},"source":["#### collate 関数の準備"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IEIzT_4geGBd"},"outputs":[],"source":["def sup_train_collate_fn(\n","    examples: list[dict],\n",") -> dict[str, BatchEncoding | Tensor]:\n","    \"\"\"訓練セットのミニバッチを作成\"\"\"\n","    premises = []\n","    hypotheses = []\n","\n","    for example in examples:\n","        premises.append(example[\"premise\"])\n","\n","        entailment_hypothesis = example[\"entailment_hypothesis\"]\n","        contradiction_hypothesis = example[\"contradiction_hypothesis\"]\n","\n","        hypotheses.extend(\n","            [entailment_hypothesis, contradiction_hypothesis]\n","        )\n","\n","    # ミニバッチに含まれる前提文と仮説文にトークナイザを適用する\n","    tokenized_premises = tokenizer(\n","        premises,\n","        padding=True,\n","        truncation=True,\n","        max_length=32,\n","        return_tensors=\"pt\",\n","    )\n","    tokenized_hypotheses = tokenizer(\n","        hypotheses,\n","        padding=True,\n","        truncation=True,\n","        max_length=32,\n","        return_tensors=\"pt\",\n","    )\n","\n","    # 前提文と仮説文の類似度行列における正例ペアの位置を示すTensorを作成する\n","    # 行列のi行目の事例（前提文）に対して\n","    # 2*i列目の要素（仮説文）が正例ペアとなる\n","    labels = torch.arange(0, 2 * len(premises), 2)\n","\n","    return {\n","        \"tokenized_texts_1\": tokenized_premises,\n","        \"tokenized_texts_2\": tokenized_hypotheses,\n","        \"labels\": labels,\n","    }"]},{"cell_type":"markdown","metadata":{"id":"L3DNYbgheGBd"},"source":["#### モデルの準備"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e5AiG2QNeGBe","outputId":"1da35960-896f-4a7e-ed3d-9c536bb47bc5"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at cl-tohoku/bert-base-japanese-v3 were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}],"source":["# 教師ありSimCSEのモデルを初期化する\n","sup_model = SimCSEModel(base_model_name, mlp_only_train=False)"]},{"cell_type":"markdown","metadata":{"id":"pgYchOXseGBe"},"source":["#### `Trainer` の準備"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vTdBPvrieGBe"},"outputs":[],"source":["# 教師ありSimCSEの訓練のハイパーパラメータを設定する\n","sup_training_args = TrainingArguments(\n","    output_dir=\"outputs_sup_simcse\",  # 結果の保存先フォルダ\n","    per_device_train_batch_size=128,  # 訓練時のバッチサイズ\n","    per_device_eval_batch_size=128,  # 評価時のバッチサイズ\n","    learning_rate=5e-5,  # 学習率\n","    num_train_epochs=3,  # 訓練エポック数\n","    evaluation_strategy=\"steps\",  # 検証セットによる評価のタイミング\n","    eval_steps=250,  # 検証セットによる評価を行う訓練ステップ数の間隔\n","    logging_steps=250,  # ロギングを行う訓練ステップ数の間隔\n","    save_steps=250,  # チェックポイントを保存する訓練ステップ数の間隔\n","    save_total_limit=1,  # 保存するチェックポイントの最大数\n","    fp16=True,  # 自動混合精度演算の有効化\n","    load_best_model_at_end=True,  # 最良のモデルを訓練終了後に読み込むか\n","    metric_for_best_model=\"spearman\",  # 最良のモデルを決定する評価指標\n","    remove_unused_columns=False,  # データセットの不要フィールドを削除するか\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rYAw2inaeGBe"},"outputs":[],"source":["# 教師ありSimCSEのTrainerを初期化する\n","sup_trainer = SimCSETrainer(\n","    model=sup_model,\n","    args=sup_training_args,\n","    data_collator=sup_train_collate_fn,\n","    train_dataset=sup_train_dataset,\n","    eval_dataset=valid_dataset,\n","    compute_metrics=compute_metrics,\n",")"]},{"cell_type":"markdown","metadata":{"id":"7gCwVGRgeGBe"},"source":["#### 訓練の実行"]},{"cell_type":"code","source":["# 教師ありSimCSEの訓練を行う\n","sup_trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":675},"id":"qjuT2Rtf1Cj8","outputId":"747e35aa-14ae-4704-ada8-6208e0539124"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='4065' max='4065' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [4065/4065 47:26, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Spearman</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>250</td>\n","      <td>1.435900</td>\n","      <td>2.948337</td>\n","      <td>0.793655</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>1.100400</td>\n","      <td>2.893555</td>\n","      <td>0.790319</td>\n","    </tr>\n","    <tr>\n","      <td>750</td>\n","      <td>1.007400</td>\n","      <td>2.875876</td>\n","      <td>0.789883</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.976300</td>\n","      <td>2.949479</td>\n","      <td>0.786294</td>\n","    </tr>\n","    <tr>\n","      <td>1250</td>\n","      <td>0.934300</td>\n","      <td>2.923010</td>\n","      <td>0.793312</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>0.829400</td>\n","      <td>2.985832</td>\n","      <td>0.796338</td>\n","    </tr>\n","    <tr>\n","      <td>1750</td>\n","      <td>0.755600</td>\n","      <td>3.013074</td>\n","      <td>0.794263</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>0.759800</td>\n","      <td>2.999113</td>\n","      <td>0.795966</td>\n","    </tr>\n","    <tr>\n","      <td>2250</td>\n","      <td>0.750100</td>\n","      <td>2.957278</td>\n","      <td>0.799006</td>\n","    </tr>\n","    <tr>\n","      <td>2500</td>\n","      <td>0.730800</td>\n","      <td>2.964985</td>\n","      <td>0.799876</td>\n","    </tr>\n","    <tr>\n","      <td>2750</td>\n","      <td>0.712500</td>\n","      <td>3.031944</td>\n","      <td>0.793972</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>0.607200</td>\n","      <td>3.034683</td>\n","      <td>0.798553</td>\n","    </tr>\n","    <tr>\n","      <td>3250</td>\n","      <td>0.609300</td>\n","      <td>3.021175</td>\n","      <td>0.797094</td>\n","    </tr>\n","    <tr>\n","      <td>3500</td>\n","      <td>0.609500</td>\n","      <td>3.038929</td>\n","      <td>0.798101</td>\n","    </tr>\n","    <tr>\n","      <td>3750</td>\n","      <td>0.609900</td>\n","      <td>3.030463</td>\n","      <td>0.800927</td>\n","    </tr>\n","    <tr>\n","      <td>4000</td>\n","      <td>0.607400</td>\n","      <td>3.029306</td>\n","      <td>0.799522</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=4065, training_loss=0.8116521856441709, metrics={'train_runtime': 2847.1429, 'train_samples_per_second': 182.75, 'train_steps_per_second': 1.428, 'total_flos': 0.0, 'train_loss': 0.8116521856441709, 'epoch': 3.0})"]},"metadata":{},"execution_count":36}]},{"cell_type":"markdown","metadata":{"id":"vE1ThUDreGBf"},"source":["#### 性能評価"]},{"cell_type":"code","source":["# 検証セットで教師ありSimCSEのモデルの評価を行う\n","sup_trainer.evaluate(valid_dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":154},"id":"H6slYrjvAyoH","outputId":"421f162f-263e-4f94-fb50-b66f8b52a36d"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='195' max='195' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [195/195 00:16]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["{'eval_loss': 3.030463457107544,\n"," 'eval_spearman': 0.8009272526316298,\n"," 'eval_runtime': 16.6266,\n"," 'eval_samples_per_second': 748.862,\n"," 'eval_steps_per_second': 5.894,\n"," 'epoch': 3.0}"]},"metadata":{},"execution_count":37}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":154},"id":"_YK_i0tteGBf","outputId":"29c75457-366e-4aa6-8d40-bc968d2f5003"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='218' max='195' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [195/195 00:23]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["{'eval_loss': 2.5370500087738037,\n"," 'eval_spearman': 0.8158127715454032,\n"," 'eval_runtime': 2.1569,\n"," 'eval_samples_per_second': 675.501,\n"," 'eval_steps_per_second': 5.563,\n"," 'epoch': 3.0}"]},"metadata":{},"execution_count":38}],"source":["# テストセットで教師ありSimCSEのモデルの評価を行う\n","sup_trainer.evaluate(test_dataset)"]},{"cell_type":"markdown","metadata":{"id":"6XThheZc5qJR"},"source":["#### Google ドライブへの保存"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1gFv3xYZ5qJT"},"outputs":[],"source":["# 保存されたモデルをGoogleドライブのフォルダにコピーする\n","!cp -r outputs_sup_simcse drive/MyDrive/llm-book"]}]}