{"cells":[{"cell_type":"markdown","metadata":{"id":"aQ2KGyLJ99Yi"},"source":["# LangChainの準備"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mkPbwp6-ploX"},"outputs":[],"source":["# パッケージのインストール\n","!pip install langchain==0.0.181\n","!pip install openai"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_Gf8Rfw2MiG_"},"outputs":[],"source":["# 環境変数の準備\n","import os\n","os.environ[\"OPENAI_API_KEY\"] = \"<OpenAI_APIのAPIキー>\""]},{"cell_type":"markdown","metadata":{"id":"YPJ2lQW0-J3a"},"source":["# テキスト生成モデルのLLM呼び出し"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YBYKjuiZBAXn"},"outputs":[],"source":["from langchain.llms import OpenAI\n","\n","# LLMの準備\n","llm = OpenAI(\n","    model_name=\"text-davinci-003\",  # モデルID\n","    temperature=0  # ランダムさ\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XNWwnfTBrhNJ"},"outputs":[],"source":["# LLMの呼び出し\n","result = llm(\"ネコの鳴き声は？\")\n","print(result)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OZ-l9ky6x3I8"},"outputs":[],"source":["# 高度なLLMの呼び出し\n","result = llm.generate([\"猫の鳴き声は？\", \"カラスの鳴き声は？\"])\n","\n","# 出力テキスト\n","print(\"response0:\", result.generations[0][0].text)\n","print(\"response1:\", result.generations[1][0].text)\n","\n","# 使用したトークン数\n","print(\"llm_output:\", result.llm_output)"]},{"cell_type":"markdown","metadata":{"id":"Cm1RHdPjrhX2"},"source":["# チャットモデルのLLM呼び出し"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LQOSHZfzkvlY"},"outputs":[],"source":["from langchain.chat_models import ChatOpenAI\n","\n","# LLMの準備\n","chat_llm = ChatOpenAI(\n","    model_name=\"gpt-3.5-turbo\",  # モデルID\n","    temperature=0  # ランダムさ\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s5vQ7muHrxg4"},"outputs":[],"source":["from langchain.schema import (\n","    SystemMessage,\n","    HumanMessage,\n","    AIMessage\n",")\n","\n","# LLMの呼び出し\n","messages = [\n","    HumanMessage(content=\"ネコの鳴き声は？\")\n","]\n","result = chat_llm(messages)\n","print(result)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JOUbE8-XxGkU"},"outputs":[],"source":["# 高度なLLMの呼び出し\n","messages_list = [\n","    [HumanMessage(content=\"ネコの鳴き声は？\")],\n","    [HumanMessage(content=\"カラスの鳴き声は？\")]\n","]\n","result = chat_llm.generate(messages_list)\n","\n","# 出力テキスト\n","print(\"response0:\", result.generations[0][0].text)\n","print(\"response1:\", result.generations[1][0].text)\n","\n","# 使用したトークン数\n","print(\"llm_output:\", result.llm_output)"]},{"cell_type":"markdown","metadata":{"id":"x1PIjv-pllHE"},"source":["# キャッシュの有効化"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OSNGZIhOlRTq"},"outputs":[],"source":["import langchain\n","from langchain.cache import InMemoryCache\n","\n","# キャッシュの有効化\n","langchain.llm_cache = InMemoryCache()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Vpl3by-UlkEq"},"outputs":[],"source":["# 初回のLLM呼び出し\n","llm.generate([\"空の色は？\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kiAWmyCmlMmq"},"outputs":[],"source":["# 2回目以降のLLM呼び出し\n","llm.generate([\"空の色は？\"])"]},{"cell_type":"markdown","metadata":{"id":"BVGJochJoDRI"},"source":["# 特定のLLMのキャッシュの無効化"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ciUncDwyoE3u"},"outputs":[],"source":["# 特定のLLMのキャッシュの無効化\n","llm = OpenAI(cache=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3gzGXoPjo6uE"},"outputs":[],"source":["# LLM呼び出し\n","llm.generate([\"空の色は？\"])"]},{"cell_type":"markdown","metadata":{"id":"uRhplZMApPHY"},"source":["# キャッシュの無効化"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f1Sz4rNApK11"},"outputs":[],"source":["# キャッシュの無効化\n","langchain.llm_cache = None"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z7zHImzmriiV"},"outputs":[],"source":["# LLM呼び出し\n","llm.generate([\"空の色は？\"])"]},{"cell_type":"markdown","metadata":{"id":"JOkBvnG0o7OV"},"source":["# LLMの非同期処理"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wW6szBSZo87d"},"outputs":[],"source":["import time\n","from langchain.llms import OpenAI\n","\n","# 同期処理で10回呼び出しの関数\n","def generate_serially():\n","    llm = OpenAI(temperature=0.9)\n","    for _ in range(10):\n","        resp = llm.generate([\"こんにちは！\"])\n","        print(resp.generations[0][0].text)\n","\n","\n","# 時間計測の開始\n","s = time.perf_counter()\n","\n","# 同期処理で10回呼び出し\n","generate_serially()\n","\n","# 時間計測の完了\n","elapsed = time.perf_counter() - s\n","print(f\"{elapsed:0.2f} 秒\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rP9GZ6NTpBAZ"},"outputs":[],"source":["import asyncio\n","\n","# イベントループをネストする設定\n","import nest_asyncio\n","nest_asyncio.apply()\n","\n","# 非同期処理で1回呼び出しの関数\n","async def async_generate(llm):\n","    resp = await llm.agenerate([\"こんにちは！\"])\n","    print(resp.generations[0][0].text)\n","\n","# 非同期処理で10回呼び出しの関数\n","async def generate_concurrently():\n","    llm = OpenAI(temperature=0.9)\n","    tasks = [async_generate(llm) for _ in range(10)]\n","    await asyncio.gather(*tasks)\n","\n","\n","# 時間計測の開始\n","s = time.perf_counter()\n","\n","# 非同期処理で10回呼び出し\n","asyncio.run(generate_concurrently())\n","\n","# 時間計測の完了\n","elapsed = time.perf_counter() - s\n","print(f\"{elapsed:0.2f} 秒\")"]},{"cell_type":"markdown","metadata":{"id":"9WnL2UytsNTz"},"source":["# LLMのストリーミング"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"IH-PAwYssMuE"},"outputs":[],"source":["from langchain.llms import OpenAI\n","from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n","\n","# ストリーミング出力するLLMの準備\n","llm = OpenAI(\n","    streaming=True,\n","    callbacks=[StreamingStdOutCallbackHandler()],\n","    verbose=True,\n","    temperature=0\n",")\n","\n","# LLM呼び出し\n","resp = llm(\"楽しいChatGPT生活を歌詞にしてください。\")"]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMvQq897BKCljJuQeZyoJr1"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}