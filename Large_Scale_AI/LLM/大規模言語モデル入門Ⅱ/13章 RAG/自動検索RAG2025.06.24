ç¾åœ¨ã®ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°çŠ¶æ³ã€€2025/06/24
ãƒ»

*   æœ¬ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚³ãƒ¼ãƒ‰ã¯ã™ã¹ã¦å®Œäº†
*   ãƒ—ãƒ­ã‚°ãƒ©ãƒ ãŒå‡ºã™çµæœã¯æƒ…å ±é‡ãŒå°‘ãªã„ã®ã§æ”¹è‰¯ã™ã‚‹äºˆå®š
*   ãƒªã‚¹ãƒˆé …ç›®
*   ãƒªã‚¹ãƒˆé …ç›®





RAGãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆã‚¢ã®è‡ªå‹•æ§‹ç¯‰

!apt-get install git

!git clone https://github.com/noriaki555/Large-Scale-AI-rep

from huggingface_hub import notebook_login

# Hugging Face Hubã«ãƒ­ã‚°ã‚¤ãƒ³
notebook_login()
#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

!pip install --upgrade openai

import openai

# ç’°å¢ƒå¤‰æ•°ã«APIã‚­ãƒ¼ã‚’è¨­å®šï¼ˆç›´æ¥ä»£å…¥ã§ã‚‚å¯ï¼‰
SERPAPI_KEY = "015b517bf20e4b91fac64fb822ce36f91f857d8c5a31626982c3bbe43bed7023"
#OPENAI_API#_KEY = "YOUR_OPENAI_API_KEY"
openai.api_key = "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"
#SERPAPI_KEY:015b517bf20e4b91fac64fb822ce36f91f857d8c5a31626982c3bbe43bed7023
#OPENAI_API_KEY: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

!pip install serpapi
!pip install faiss-cpu
#!pip install faiss-gpu
!pip install numpy

!pip install --upgrade serpapi
!pip show serpapi

!pip install google-search-results

!pip install transformers

!pip show openai


#RAGãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆã‚¢ã®è‡ªå‹•æ§‹ç¯‰
import requests
from bs4 import BeautifulSoup
import openai
from serpapi import GoogleSearch
from transformers import RagTokenizer, RagRetriever, RagSequenceForGeneration
import faiss
import numpy as np

# Environment variable or direct assignment for API keys
SERPAPI_KEY = "015b517bf20e4b91fac64fb822ce36f91f857d8c5a31626982c3bbe43bed7023"
OPENAI_API_KEY = "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"

# Initialize OpenAI client with API key
client = openai.OpenAI(api_key=OPENAI_API_KEY)

def web_search(query, num_results=3):
    params = {
        "engine": "google",
        "q": query,
        "api_key": SERPAPI_KEY,
        "num": num_results,
    }
    search = GoogleSearch(params)
    results = search.get_dict()
    return [r["link"] for r in results.get("organic_results", [])[:num_results]]

def fetch_and_clean(url):
    try:
        response = requests.get(url, timeout=5)
        soup = BeautifulSoup(response.text, "html.parser")
        texts = [p.get_text() for p in soup.find_all("p")]
        return "\n".join(texts).strip()
    except Exception as e:
        print(f"Error fetching {url}: {e}")
        return ""

def summarize_text(text, max_tokens=300):
    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": "ä»¥ä¸‹ã®é•·æ–‡ã‚’RAGç”¨ã«ç°¡æ½”ã«è¦ç´„ã—ã¦ãã ã•ã„ã€‚"},
            {"role": "user", "content": text[:3000]},  # OpenAI tokenåˆ¶é™ã‚’è€ƒæ…®
        ],
        max_tokens=max_tokens,
        temperature=0.3
    )
    return response.choices[0].message.content

def get_embedding(text):
    response = client.embeddings.create(
        input=[text],
        model="text-embedding-3-small"
    )
    return np.array(response.data[0].embedding, dtype="float32")

def create_vector_store(docs):
    dim = len(docs[0][1])
    index = faiss.IndexFlatL2(dim)
    texts = []
    for text, vector in docs:
        index.add(np.array([vector]))
        texts.append(text)
    return index, texts

def rag_respond(query, index, texts):
    q_vector = get_embedding(query)
    D, I = index.search(np.array([q_vector]), k=1)
    context = texts[I[0][0]]

    response = client.chat.completions.create(
        model="gpt-4",
        messages=[
            {"role": "system", "content": "ä»¥ä¸‹ã®ã‚³ãƒ³textã‚’å…ƒã«ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«ç­”ãˆã¦ãã ã•ã„ã€‚"},
            {"role": "user", "content": f"Context: {context}\n\nQuestion: {query}"},
        ],
        temperature=0.5,
        max_tokens=300
    )
    return response.choices[0].message.content

# === å®Ÿè¡Œä¾‹ ===
if __name__ == "__main__":
    query = "æœ€æ–°ã®æ ¸èåˆç‚‰ã®å‹•å‘ã¯ï¼Ÿ"
    urls = web_search(query)
    print("æ¤œç´¢URL:", urls)

    docs = []
    for url in urls:
        text = fetch_and_clean(url)
        if text:
            summary = summarize_text(text)
            embedding = get_embedding(summary)
            docs.append((summary, embedding))

    if docs:
        index, texts = create_vector_store(docs)
        answer = rag_respond(query, index, texts)
        print("\nğŸ§  å›ç­”:\n", answer)
    else:
        print("âŒ æœ‰åŠ¹ãªæƒ…å ±ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
