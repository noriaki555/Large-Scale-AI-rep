{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNFc9dvPc8SQ+dJRgOwP+hU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Appendix E: Parameter-efficient Finetuning with LoRA"],"metadata":{"id":"jV05P3hkCZSL"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"uMHQPMVaIt35"},"outputs":[],"source":["from importlib.metadata import version\n","\n","pkgs = [\"matplotlib\",\n","        \"numpy\",\n","        \"tiktoken\",\n","        \"torch\",\n","        \"tensorflow\", # For OpenAI's pretrained weights\n","        \"pandas\"      # Dataset loading\n","       ]\n","for p in pkgs:\n","    print(f\"{p} version: {version(p)}\")"]},{"cell_type":"markdown","source":["E.1 Introduction to LoRA"],"metadata":{"id":"A1PuW7KYCzl3"}},{"cell_type":"markdown","source":["E.2 Preparing the dataset"],"metadata":{"id":"h2UrYQQODGX_"}},{"cell_type":"code","source":["import urllib\n","from pathlib import Path\n","import pandas as pd\n","from previous_chapters import (\n","    download_and_unzip_spam_data,\n","    create_balanced_dataset,\n","    random_split\n",")\n","# If the `previous_chapters.py` file is not available locally,\n","# you can import it from the `llms-from-scratch` PyPI package.\n","# For details, see: https://github.com/rasbt/LLMs-from-scratch/tree/main/pkg\n","# E.g.,\n","# from llms_from_scratch.ch06 import (\n","#     download_and_unzip_spam_data,\n","#     create_balanced_dataset,\n","#     random_split\n","# )\n","\n","\n","\n","url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n","zip_path = \"sms_spam_collection.zip\"\n","extracted_path = \"sms_spam_collection\"\n","data_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\"\n","\n","try:\n","    download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)\n","except (urllib.error.HTTPError, urllib.error.URLError, TimeoutError) as e:\n","    print(f\"Primary URL failed: {e}. Trying backup URL...\")\n","    url = \"https://f001.backblazeb2.com/file/LLMs-from-scratch/sms%2Bspam%2Bcollection.zip\"\n","    download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)\n","\n","df = pd.read_csv(data_file_path, sep=\"\\t\", header=None, names=[\"Label\", \"Text\"])\n","balanced_df = create_balanced_dataset(df)\n","balanced_df[\"Label\"] = balanced_df[\"Label\"].map({\"ham\": 0, \"spam\": 1})\n","\n","train_df, validation_df, test_df = random_split(balanced_df, 0.7, 0.1)\n","train_df.to_csv(\"train.csv\", index=None)\n","validation_df.to_csv(\"validation.csv\", index=None)\n","test_df.to_csv(\"test.csv\", index=None)"],"metadata":{"id":"Amk1GPASCu83"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import tiktoken\n","from previous_chapters import SpamDataset\n","\n","\n","tokenizer = tiktoken.get_encoding(\"gpt2\")\n","train_dataset = SpamDataset(\"train.csv\", max_length=None, tokenizer=tokenizer)\n","val_dataset = SpamDataset(\"validation.csv\", max_length=train_dataset.max_length, tokenizer=tokenizer)\n","test_dataset = SpamDataset(\"test.csv\", max_length=train_dataset.max_length, tokenizer=tokenizer)"],"metadata":{"id":"peJxAS2eDZHn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import tiktoken\n","from previous_chapters import SpamDataset\n","\n","\n","tokenizer = tiktoken.get_encoding(\"gpt2\")\n","train_dataset = SpamDataset(\"train.csv\", max_length=None, tokenizer=tokenizer)\n","val_dataset = SpamDataset(\"validation.csv\", max_length=train_dataset.max_length, tokenizer=tokenizer)\n","test_dataset = SpamDataset(\"test.csv\", max_length=train_dataset.max_length, tokenizer=tokenizer)"],"metadata":{"id":"eWiwCte-Dhr1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import DataLoader\n","\n","num_workers = 0\n","batch_size = 8\n","\n","torch.manual_seed(123)\n","\n","train_loader = DataLoader(\n","    dataset=train_dataset,\n","    batch_size=batch_size,\n","    shuffle=True,\n","    num_workers=num_workers,\n","    drop_last=True,\n",")\n","\n","val_loader = DataLoader(\n","    dataset=val_dataset,\n","    batch_size=batch_size,\n","    num_workers=num_workers,\n","    drop_last=False,\n",")\n","\n","test_loader = DataLoader(\n","    dataset=test_dataset,\n","    batch_size=batch_size,\n","    num_workers=num_workers,\n","    drop_last=False,\n",")"],"metadata":{"id":"NiPQacWvD789"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"Train loader:\")\n","for input_batch, target_batch in train_loader:\n","    pass\n","\n","print(\"Input batch dimensions:\", input_batch.shape)\n","print(\"Label batch dimensions\", target_batch.shape)"],"metadata":{"id":"VC1wvs2tELXH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(f\"{len(train_loader)} training batches\")\n","print(f\"{len(val_loader)} validation batches\")\n","print(f\"{len(test_loader)} test batches\")"],"metadata":{"id":"cSWlgPnkEVoH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["E.3 Initializing the model"],"metadata":{"id":"EOiH2GuKEdUw"}},{"cell_type":"code","source":["from gpt_download import download_and_load_gpt2\n","from previous_chapters import GPTModel, load_weights_into_gpt\n","# Alternatively:\n","# from llms_from_scratch.ch04 import GPTModel\n","# from llms_from_scratch.ch05 import load_weights_into_gpt\n","\n","\n","\n","CHOOSE_MODEL = \"gpt2-small (124M)\"\n","INPUT_PROMPT = \"Every effort moves\"\n","\n","BASE_CONFIG = {\n","    \"vocab_size\": 50257,     # Vocabulary size\n","    \"context_length\": 1024,  # Context length\n","    \"drop_rate\": 0.0,        # Dropout rate\n","    \"qkv_bias\": True         # Query-key-value bias\n","}\n","\n","model_configs = {\n","    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n","    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n","    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n","    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n","}\n","\n","BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n","\n","model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n","settings, params = download_and_load_gpt2(model_size=model_size, models_dir=\"gpt2\")\n","\n","model = GPTModel(BASE_CONFIG)\n","load_weights_into_gpt(model, params)\n","model.eval();"],"metadata":{"id":"EF8KwtJiEWAf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from previous_chapters import (\n","    generate_text_simple,\n","    text_to_token_ids,\n","    token_ids_to_text\n",")\n","\n","\n","text_1 = \"Every effort moves you\"\n","\n","token_ids = generate_text_simple(\n","    model=model,\n","    idx=text_to_token_ids(text_1, tokenizer),\n","    max_new_tokens=15,\n","    context_size=BASE_CONFIG[\"context_length\"]\n",")\n","\n","print(token_ids_to_text(token_ids, tokenizer))"],"metadata":{"id":"w4sL2_YQEWgP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch.manual_seed(123)\n","\n","num_classes = 2\n","model.out_head = torch.nn.Linear(in_features=768, out_features=num_classes)"],"metadata":{"id":"2hp3vOd5FOeH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Note:\n","# Uncommenting the following lines will allow the code to run on Apple Silicon chips, if applicable,\n","# which is approximately 1.2x faster than on an Apple CPU (as measured on an M3 MacBook Air).\n","# However, the resulting loss values may be slightly different.\n","\n","#if torch.cuda.is_available():\n","#    device = torch.device(\"cuda\")\n","#elif torch.backends.mps.is_available():\n","#    device = torch.device(\"mps\")\n","#else:\n","#    device = torch.device(\"cpu\")\n","#\n","# print(f\"Using {device} device.\")\n","\n","model.to(device);  # no assignment model = model.to(device) necessary for nn.Module classes"],"metadata":{"id":"P9g5330eFOTh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from previous_chapters import calc_accuracy_loader\n","# Alternatively:\n","# from llms_from_scratch.ch06 import calc_accuracy_loader\n","\n","\n","\n","torch.manual_seed(123)\n","train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=10)\n","val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=10)\n","test_accuracy = calc_accuracy_loader(test_loader, model, device, num_batches=10)\n","\n","print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n","print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n","print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"],"metadata":{"id":"yaE1C-SYFOIG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["E.4 Parameter-efficient finetuning with LoRA"],"metadata":{"id":"d2IbDK2IGFEW"}},{"cell_type":"code","source":["import math\n","\n","class LoRALayer(torch.nn.Module):\n","    def __init__(self, in_dim, out_dim, rank, alpha):\n","        super().__init__()\n","        self.A = torch.nn.Parameter(torch.empty(in_dim, rank))\n","        torch.nn.init.kaiming_uniform_(self.A, a=math.sqrt(5))  # similar to standard weight initialization\n","        self.B = torch.nn.Parameter(torch.zeros(rank, out_dim))\n","        self.alpha = alpha\n","\n","    def forward(self, x):\n","        x = self.alpha * (x @ self.A @ self.B)\n","        return x"],"metadata":{"id":"BY_uAPHWFN8O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class LinearWithLoRA(torch.nn.Module):\n","    def __init__(self, linear, rank, alpha):\n","        super().__init__()\n","        self.linear = linear\n","        self.lora = LoRALayer(\n","            linear.in_features, linear.out_features, rank, alpha\n","        )\n","\n","    def forward(self, x):\n","        return self.linear(x) + self.lora(x)"],"metadata":{"id":"wSJZYiwsGVn-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def replace_linear_with_lora(model, rank, alpha):\n","    for name, module in model.named_children():\n","        if isinstance(module, torch.nn.Linear):\n","            # Replace the Linear layer with LinearWithLoRA\n","            setattr(model, name, LinearWithLoRA(module, rank, alpha))\n","        else:\n","            # Recursively apply the same function to child modules\n","            replace_linear_with_lora(module, rank, alpha)"],"metadata":{"id":"6r8s5NFTGVi8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n","print(f\"Total trainable parameters before: {total_params:,}\")\n","\n","for param in model.parameters():\n","    param.requires_grad = False\n","\n","total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n","print(f\"Total trainable parameters after: {total_params:,}\")"],"metadata":{"id":"Es1U1bkcGVdv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["replace_linear_with_lora(model, rank=16, alpha=16)\n","\n","total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n","print(f\"Total trainable LoRA parameters: {total_params:,}\")"],"metadata":{"id":"xpI9VdU4GVYo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","\n","print(model)"],"metadata":{"id":"HDXNiIgTGVUR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch.manual_seed(123)\n","train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=10)\n","val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=10)\n","test_accuracy = calc_accuracy_loader(test_loader, model, device, num_batches=10)\n","\n","print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n","print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n","print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"],"metadata":{"id":"AwcT9cdjGVPc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import time\n","from previous_chapters import train_classifier_simple\n","# Alternatively:\n","# from llms_from_scratch.ch06 import train_classifier_simple\n","\n","\n","start_time = time.time()\n","\n","torch.manual_seed(123)\n","\n","optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.1)\n","\n","num_epochs = 5\n","train_losses, val_losses, train_accs, val_accs, examples_seen = train_classifier_simple(\n","    model, train_loader, val_loader, optimizer, device,\n","    num_epochs=num_epochs, eval_freq=50, eval_iter=5,\n",")\n","\n","end_time = time.time()\n","execution_time_minutes = (end_time - start_time) / 60\n","print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"],"metadata":{"id":"j9iAOYerGVJV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from previous_chapters import plot_values\n","# Alternatively:\n","# from llms_from_scratch.ch06 import plot_values\n","\n","epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n","examples_seen_tensor = torch.linspace(0, examples_seen, len(train_losses))\n","\n","plot_values(epochs_tensor, examples_seen_tensor, train_losses, val_losses, label=\"loss\")"],"metadata":{"id":"eh8mzoOgFNvO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_accuracy = calc_accuracy_loader(train_loader, model, device)\n","val_accuracy = calc_accuracy_loader(val_loader, model, device)\n","test_accuracy = calc_accuracy_loader(test_loader, model, device)\n","\n","print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n","print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n","print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"],"metadata":{"id":"OgzdTjIuHkTF"},"execution_count":null,"outputs":[]}]}