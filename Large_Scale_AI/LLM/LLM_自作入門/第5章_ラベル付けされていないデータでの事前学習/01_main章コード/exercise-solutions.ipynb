{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOh6L6Vkb1twEf5DpKJYSvg"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Chapter 5 Exercise solutions"],"metadata":{"id":"qBC_9yXaXuBc"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"fCD3qjzpa9hN"},"outputs":[],"source":["from importlib.metadata import version\n","\n","pkgs = [\"numpy\",\n","        \"tiktoken\",\n","        \"torch\",\n","        \"tensorflow\" # For OpenAI's pretrained weights\n","       ]\n","for p in pkgs:\n","    print(f\"{p} version: {version(p)}\")"]},{"cell_type":"markdown","source":["Exercise 5.1: Temperature-scaled softmax scores and sampling probabilities"],"metadata":{"id":"PiyAe4HVYB5Z"}},{"cell_type":"code","source":["import torch\n","\n","vocab = {\n","    \"closer\": 0,\n","    \"every\": 1,\n","    \"effort\": 2,\n","    \"forward\": 3,\n","    \"inches\": 4,\n","    \"moves\": 5,\n","    \"pizza\": 6,\n","    \"toward\": 7,\n","    \"you\": 8,\n","}\n","inverse_vocab = {v: k for k, v in vocab.items()}\n","\n","next_token_logits = torch.tensor(\n","    [4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79]\n",")\n","\n","def print_sampled_tokens(probas):\n","    torch.manual_seed(123)\n","    sample = [torch.multinomial(probas, num_samples=1).item() for i in range(1_000)]\n","    sampled_ids = torch.bincount(torch.tensor(sample))\n","    for i, freq in enumerate(sampled_ids):\n","        print(f\"{freq} x {inverse_vocab[i]}\")\n","\n","\n","def softmax_with_temperature(logits, temperature):\n","    scaled_logits = logits / temperature\n","    return torch.softmax(scaled_logits, dim=0)\n","\n","\n","temperatures = [1, 0.1, 5]  # Original, higher, and lower temperature\n","scaled_probas = [softmax_with_temperature(next_token_logits, T) for T in temperatures]"],"metadata":{"id":"wvYFjGYTX4vD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i, probas in enumerate(scaled_probas):\n","    print(\"\\n\\nTemperature:\", temperatures[i])\n","    print_sampled_tokens(probas)"],"metadata":{"id":"J7OZHvFrYR8r"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Exercise 5.2: Different temperature and top-k settings"],"metadata":{"id":"gERj-gzBYnSC"}},{"cell_type":"markdown","source":["Exercise 5.3: Deterministic behavior in the decoding functions"],"metadata":{"id":"uBePF2lpY9-g"}},{"cell_type":"code","source":["import tiktoken\n","import torch\n","from previous_chapters import GPTModel\n","\n","\n","GPT_CONFIG_124M = {\n","    \"vocab_size\": 50257,  # Vocabulary size\n","    \"context_length\": 256,       # Shortened context length (orig: 1024)\n","    \"emb_dim\": 768,       # Embedding dimension\n","    \"n_heads\": 12,        # Number of attention heads\n","    \"n_layers\": 12,       # Number of layers\n","    \"drop_rate\": 0.1,     # Dropout rate\n","    \"qkv_bias\": False     # Query-key-value bias\n","}\n","\n","\n","torch.manual_seed(123)\n","\n","tokenizer = tiktoken.get_encoding(\"gpt2\")\n","model = GPTModel(GPT_CONFIG_124M)\n","model.load_state_dict(torch.load(\"model.pth\", weights_only=True))\n","model.eval();"],"metadata":{"id":"jOJnHXWzYeMg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from gpt_generate import generate, text_to_token_ids, token_ids_to_text\n","from previous_chapters import generate_text_simple"],"metadata":{"id":"sLYfI8PeZNIU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Deterministic function that used torch.argmax\n","\n","start_context = \"Every effort moves you\"\n","\n","token_ids = generate_text_simple(\n","    model=model,\n","    idx=text_to_token_ids(start_context, tokenizer),\n","    max_new_tokens=25,\n","    context_size=GPT_CONFIG_124M[\"context_length\"]\n",")\n","\n","print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"],"metadata":{"id":"iA2K0SejZVk5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Deterministic behavior: No top_k, no temperature scaling\n","\n","token_ids = generate(\n","    model=model,\n","    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n","    max_new_tokens=25,\n","    context_size=GPT_CONFIG_124M[\"context_length\"],\n","    top_k=None,\n","    temperature=0.0\n",")\n","\n","print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"],"metadata":{"id":"1I75_FksZh1w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Deterministic behavior: No top_k, no temperature scaling\n","\n","token_ids = generate(\n","    model=model,\n","    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n","    max_new_tokens=25,\n","    context_size=GPT_CONFIG_124M[\"context_length\"],\n","    top_k=None,\n","    temperature=0.0\n",")\n","\n","print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"],"metadata":{"id":"YdA4paxuZtXS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Exercise 5.4: Continued pretraining"],"metadata":{"id":"bBk9rhMKZ_Hh"}},{"cell_type":"code","source":["import tiktoken\n","import torch\n","from previous_chapters import GPTModel\n","\n","\n","GPT_CONFIG_124M = {\n","    \"vocab_size\": 50257,   # Vocabulary size\n","    \"context_length\": 256, # Shortened context length (orig: 1024)\n","    \"emb_dim\": 768,        # Embedding dimension\n","    \"n_heads\": 12,         # Number of attention heads\n","    \"n_layers\": 12,        # Number of layers\n","    \"drop_rate\": 0.1,      # Dropout rate\n","    \"qkv_bias\": False      # Query-key-value bias\n","}\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","tokenizer = tiktoken.get_encoding(\"gpt2\")\n","\n","checkpoint = torch.load(\"model_and_optimizer.pth\", weights_only=True)\n","model = GPTModel(GPT_CONFIG_124M)\n","model.load_state_dict(checkpoint[\"model_state_dict\"])\n","model.to(device)\n","\n","optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n","optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n","model.train();"],"metadata":{"id":"AFlfK1wOZ3mq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import urllib.request\n","from previous_chapters import create_dataloader_v1\n","\n","\n","file_path = \"the-verdict.txt\"\n","url = \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/the-verdict.txt\"\n","\n","if not os.path.exists(file_path):\n","    with urllib.request.urlopen(url) as response:\n","        text_data = response.read().decode('utf-8')\n","    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n","        file.write(text_data)\n","else:\n","    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n","        text_data = file.read()\n","\n","\n","# Train/validation ratio\n","train_ratio = 0.90\n","split_idx = int(train_ratio * len(text_data))\n","train_data = text_data[:split_idx]\n","val_data = text_data[split_idx:]\n","\n","\n","torch.manual_seed(123)\n","\n","train_loader = create_dataloader_v1(\n","    train_data,\n","    batch_size=2,\n","    max_length=GPT_CONFIG_124M[\"context_length\"],\n","    stride=GPT_CONFIG_124M[\"context_length\"],\n","    drop_last=True,\n","    shuffle=True,\n","    num_workers=0\n",")\n","\n","val_loader = create_dataloader_v1(\n","    val_data,\n","    batch_size=2,\n","    max_length=GPT_CONFIG_124M[\"context_length\"],\n","    stride=GPT_CONFIG_124M[\"context_length\"],\n","    drop_last=False,\n","    shuffle=False,\n","    num_workers=0\n",")"],"metadata":{"id":"UD-OOYAYaP7h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from gpt_train import train_model_simple\n","\n","num_epochs = 1\n","train_losses, val_losses, tokens_seen = train_model_simple(\n","    model, train_loader, val_loader, optimizer, device,\n","    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n","    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",")"],"metadata":{"id":"KqDkmf_3ag2-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Exercise 5.5: Training and validation set losses of the pretrained model"],"metadata":{"id":"DwA__a6taviJ"}},{"cell_type":"code","source":["train_loss = calc_loss_loader(train_loader, gpt, device)\n","val_loss = calc_loss_loader(val_loader, gpt, device)"],"metadata":{"id":"pIRKyntMaqQI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tiktoken\n","import torch\n","from previous_chapters import GPTModel\n","\n","\n","GPT_CONFIG_124M = {\n","    \"vocab_size\": 50257,   # Vocabulary size\n","    \"context_length\": 256, # Shortened context length (orig: 1024)\n","    \"emb_dim\": 768,        # Embedding dimension\n","    \"n_heads\": 12,         # Number of attention heads\n","    \"n_layers\": 12,        # Number of layers\n","    \"drop_rate\": 0.1,      # Dropout rate\n","    \"qkv_bias\": False      # Query-key-value bias\n","}\n","\n","\n","torch.manual_seed(123)\n","\n","tokenizer = tiktoken.get_encoding(\"gpt2\")"],"metadata":{"id":"L57YYm-qa-2q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from gpt_download import download_and_load_gpt2\n","\n","settings, params = download_and_load_gpt2(model_size=\"124M\", models_dir=\"gpt2\")"],"metadata":{"id":"42IJ3PoJbLPA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define model configurations in a dictionary for compactness\n","model_configs = {\n","    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n","    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n","    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n","    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n","}\n","\n","# Copy the base configuration and update with specific model settings\n","model_name = \"gpt2-small (124M)\"  # Example model name\n","NEW_CONFIG = GPT_CONFIG_124M.copy()\n","NEW_CONFIG.update(model_configs[model_name])\n","NEW_CONFIG.update({\"context_length\": 1024, \"qkv_bias\": True})\n","\n","gpt = GPTModel(NEW_CONFIG)\n","gpt.eval();"],"metadata":{"id":"5L47c3CXbcgL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from gpt_generate import load_weights_into_gpt\n","\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","load_weights_into_gpt(gpt, params)\n","gpt.to(device);"],"metadata":{"id":"6tb-Fnw1blgY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import urllib.request\n","from previous_chapters import create_dataloader_v1\n","\n","file_path = \"the-verdict.txt\"\n","url = \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/the-verdict.txt\"\n","\n","if not os.path.exists(file_path):\n","    with urllib.request.urlopen(url) as response:\n","        text_data = response.read().decode('utf-8')\n","    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n","        file.write(text_data)\n","else:\n","    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n","        text_data = file.read()\n","\n","\n","# Train/validation ratio\n","train_ratio = 0.90\n","split_idx = int(train_ratio * len(text_data))\n","train_data = text_data[:split_idx]\n","val_data = text_data[split_idx:]\n","\n","\n","torch.manual_seed(123)\n","\n","train_loader = create_dataloader_v1(\n","    train_data,\n","    batch_size=2,\n","    max_length=GPT_CONFIG_124M[\"context_length\"],\n","    stride=GPT_CONFIG_124M[\"context_length\"],\n","    drop_last=True,\n","    shuffle=True,\n","    num_workers=0\n",")\n","\n","val_loader = create_dataloader_v1(\n","    val_data,\n","    batch_size=2,\n","    max_length=GPT_CONFIG_124M[\"context_length\"],\n","    stride=GPT_CONFIG_124M[\"context_length\"],\n","    drop_last=False,\n","    shuffle=False,\n","    num_workers=0\n",")"],"metadata":{"id":"3woX5FslbtTn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from gpt_train import calc_loss_loader\n","\n","torch.manual_seed(123) # For reproducibility due to the shuffling in the data loader\n","train_loss = calc_loss_loader(train_loader, gpt, device)\n","val_loss = calc_loss_loader(val_loader, gpt, device)\n","\n","print(\"Training loss:\", train_loss)\n","print(\"Validation loss:\", val_loss)"],"metadata":{"id":"He9GoWckb0yB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["settings, params = download_and_load_gpt2(model_size=\"1558M\", models_dir=\"gpt2\")\n","\n","model_name = \"gpt2-xl (1558M)\"\n","NEW_CONFIG = GPT_CONFIG_124M.copy()\n","NEW_CONFIG.update(model_configs[model_name])\n","NEW_CONFIG.update({\"context_length\": 1024, \"qkv_bias\": True})\n","\n","gpt = GPTModel(NEW_CONFIG)\n","gpt.eval()\n","\n","load_weights_into_gpt(gpt, params)\n","gpt.to(device)\n","\n","torch.manual_seed(123)\n","train_loss = calc_loss_loader(train_loader, gpt, device)\n","val_loss = calc_loss_loader(val_loader, gpt, device)\n","\n","print(\"Training loss:\", train_loss)\n","print(\"Validation loss:\", val_loss)"],"metadata":{"id":"orEnr0MjeVZn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Exercise 5.6: Trying larger models"],"metadata":{"id":"lrgdrfy8ek2I"}},{"cell_type":"code","source":["settings, params = download_and_load_gpt2(model_size=\"124M\", models_dir=\"gpt2\")\n","model_name = \"gpt2-small (124M)\""],"metadata":{"id":"Lj_uZBA9efZO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["settings, params = download_and_load_gpt2(model_size=\"1558M\", models_dir=\"gpt2\")\n","model_name = \"gpt2-xl (1558M)\""],"metadata":{"id":"FJJLuiG2exZu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tiktoken\n","import torch\n","from previous_chapters import GPTModel\n","\n","\n","GPT_CONFIG_124M = {\n","    \"vocab_size\": 50257,   # Vocabulary size\n","    \"context_length\": 256, # Shortened context length (orig: 1024)\n","    \"emb_dim\": 768,        # Embedding dimension\n","    \"n_heads\": 12,         # Number of attention heads\n","    \"n_layers\": 12,        # Number of layers\n","    \"drop_rate\": 0.1,      # Dropout rate\n","    \"qkv_bias\": False      # Query-key-value bias\n","}\n","\n","\n","tokenizer = tiktoken.get_encoding(\"gpt2\")"],"metadata":{"id":"c3-1Xd52e27f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from gpt_download import download_and_load_gpt2\n","from gpt_generate import load_weights_into_gpt\n","\n","\n","model_configs = {\n","    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n","    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n","    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n","    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n","}\n","\n","model_name = \"gpt2-xl (1558M)\"\n","NEW_CONFIG = GPT_CONFIG_124M.copy()\n","NEW_CONFIG.update(model_configs[model_name])\n","NEW_CONFIG.update({\"context_length\": 1024, \"qkv_bias\": True})\n","\n","gpt = GPTModel(NEW_CONFIG)\n","gpt.eval()\n","\n","settings, params = download_and_load_gpt2(model_size=\"1558M\", models_dir=\"gpt2\")\n","load_weights_into_gpt(gpt, params)"],"metadata":{"id":"1CNMWHSre-xu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from gpt_generate import generate, text_to_token_ids, token_ids_to_text"],"metadata":{"id":"UDYAhaSBfHv9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch.manual_seed(123)\n","\n","token_ids = generate(\n","    model=gpt,\n","    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n","    max_new_tokens=25,\n","    context_size=NEW_CONFIG[\"context_length\"],\n","    top_k=50,\n","    temperature=1.5\n",")\n","\n","print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"],"metadata":{"id":"Z8isggoefPk2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"HQEtEJQOfWQW"},"execution_count":null,"outputs":[]}]}