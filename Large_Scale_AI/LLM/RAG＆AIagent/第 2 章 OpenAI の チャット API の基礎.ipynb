{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNpt0gnTSuivQxpcq0fFbFp"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"5_6Nt4lF3Oxq"},"source":["# 2. OpenAI の チャット API の基礎\n"]},{"cell_type":"markdown","metadata":{"id":"h-ds1MBy3Oxt"},"source":["## 2.3. 入出力の長さの制限や料金に影響する「トークン」\n"]},{"cell_type":"markdown","metadata":{"id":"8lX4kLv63Oxv"},"source":["### トークン\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ca0cQQLB3Oxw"},"outputs":[],"source":["!pip install tiktoken==0.7.0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VtQJToky3Oxy"},"outputs":[],"source":["import tiktoken\n","\n","text = \"ChatGPT\"\n","\n","encoding = tiktoken.encoding_for_model(\"gpt-4o\")\n","tokens = encoding.encode(text)\n","for token in tokens:\n","    print(encoding.decode([token]))"]},{"cell_type":"markdown","metadata":{"id":"lIyw7GWH3Oxz"},"source":["### Tokenizer と tiktoken の紹介\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jJY5ukv53Ox0"},"outputs":[],"source":["import tiktoken\n","\n","text = \"LLMを使ってクールなものを作るのは簡単だが、プロダクションで使えるものを作るのは非常に難しい。\"\n","\n","encoding = tiktoken.encoding_for_model(\"gpt-4o\")\n","tokens = encoding.encode(text)\n","print(len(tokens))"]},{"cell_type":"markdown","metadata":{"id":"FzYyYnhm3Ox1"},"source":["## 2.4. Chat Completions API を試す環境の準備\n"]},{"cell_type":"markdown","metadata":{"id":"uUGTU_3S3Ox2"},"source":["### OpenAI の API キーの準備\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nFpDdZqG3Ox2"},"outputs":[],"source":["import os\n","from google.colab import userdata\n","\n","os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")"]},{"cell_type":"markdown","metadata":{"id":"OzclC2sK3Ox3"},"source":["## 2.5. Chat Completions API のハンズオン\n"]},{"cell_type":"markdown","metadata":{"id":"5rjgBbZc3Ox3"},"source":["### OpenAI のライブラリ\n"]},{"cell_type":"markdown","metadata":{"id":"OMbnV4g03Ox3"},"source":["#### 【注意】既知のエラーについて\n","\n","openai パッケージが依存する httpx のアップデートにより、`openai==1.40.6` を使用する箇所で `TypeError: Client.__init__() got an unexpected keyword argument 'proxies'` というエラーが発生するようになりました。\n","\n","このエラーは、`!pip install httpx==0.27.2` のように、httpx の特定バージョンをインストールすることで回避することができます。\n","\n","なお、Google Colab で一度上記のエラーに遭遇したあとで `!pip install httpx==0.27.2` のようにパッケージをインストールし直した場合、以下のどちらかの操作を実施する必要があります。\n","\n","- Google Colab の「ランタイム」から「セッションを再起動する」を実行する\n","- 「ランタイムを接続解除して削除」を実行してパッケージのインストールからやり直す\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4-lsjwP63Ox4"},"outputs":[],"source":["!pip install openai==1.40.6 httpx==0.27.2"]},{"cell_type":"markdown","metadata":{"id":"LvBPIAzn3Ox4"},"source":["### Chat Completions API の呼び出し\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pNIf4cSI3Ox5"},"outputs":[],"source":["from openai import OpenAI\n","\n","client = OpenAI()\n","\n","response = client.chat.completions.create(\n","    model=\"gpt-4o-mini\",\n","    messages=[\n","        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n","        {\"role\": \"user\", \"content\": \"こんにちは！私はジョンと言います！\"},\n","    ],\n",")\n","print(response.to_json(indent=2))"]},{"cell_type":"markdown","metadata":{"id":"OA_snma23Ox5"},"source":["### 会話履歴を踏まえた応答を得る\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3T-vprdA3Ox5"},"outputs":[],"source":["response = client.chat.completions.create(\n","    model=\"gpt-4o-mini\",\n","    messages=[\n","        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n","        {\"role\": \"user\", \"content\": \"こんにちは！私はジョンと言います！\"},\n","        {\"role\": \"assistant\", \"content\": \"こんにちは、ジョンさん！お会いできて嬉しいです。今日はどんなことをお話ししましょうか？\"},\n","        {\"role\": \"user\", \"content\": \"私の名前が分かりますか？\"},\n","    ],\n",")\n","print(response.to_json(indent=2))"]},{"cell_type":"markdown","metadata":{"id":"lCyjUSjs3Ox5"},"source":["### ストリーミングで応答を得る\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HLXg--Wh3Ox6"},"outputs":[],"source":["response = client.chat.completions.create(\n","    model=\"gpt-4o-mini\",\n","    messages=[\n","        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n","        {\"role\": \"user\", \"content\": \"こんにちは！私はジョンと言います！\"},\n","    ],\n","    stream=True,\n",")\n","\n","for chunk in response:\n","    content = chunk.choices[0].delta.content\n","    if content is not None:\n","        print(content, end=\"\", flush=True)"]},{"cell_type":"markdown","metadata":{"id":"yjQKnUWd3Ox6"},"source":["### JSON モード\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"drr_MeLp3Ox6"},"outputs":[],"source":["from openai import OpenAI\n","\n","client = OpenAI()\n","\n","response = client.chat.completions.create(\n","    model=\"gpt-4o-mini\",\n","    messages=[\n","        {\n","            \"role\": \"system\",\n","            \"content\": '人物一覧を次のJSON形式で出力してください。\\n{\"people\": [\"aaa\", \"bbb\"]}',\n","        },\n","        {\n","            \"role\": \"user\",\n","            \"content\": \"昔々あるところにおじいさんとおばあさんがいました\",\n","        },\n","    ],\n","    response_format={\"type\": \"json_object\"},\n",")\n","print(response.choices[0].message.content)"]},{"cell_type":"markdown","metadata":{"id":"TXcBJ_fs3Ox6"},"source":["### Vision（画像入力）\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PIir2rc73Ox7"},"outputs":[],"source":["from openai import OpenAI\n","\n","client = OpenAI()\n","\n","image_url = \"https://raw.githubusercontent.com/yoshidashingo/langchain-book/main/assets/cover.jpg\"\n","\n","response = client.chat.completions.create(\n","    model=\"gpt-4o-mini\",\n","    messages=[\n","        {\n","            \"role\": \"user\",\n","            \"content\": [\n","                {\"type\": \"text\", \"text\": \"画像を説明してください。\"},\n","                {\"type\": \"image_url\", \"image_url\": {\"url\": image_url}},\n","            ],\n","        }\n","    ],\n",")\n","\n","print(response.choices[0].message.content)"]},{"cell_type":"markdown","metadata":{"id":"H-bf6kbE3Ox7"},"source":["### （コラム）Completions API\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X2nOEcDW3Ox7"},"outputs":[],"source":["from openai import OpenAI\n","\n","client = OpenAI()\n","\n","response = client.completions.create(\n","    model=\"gpt-3.5-turbo-instruct\",\n","    prompt=\"こんにちは！私はジョンと言います！\",\n",")\n","print(response.to_json(indent=2))"]},{"cell_type":"markdown","metadata":{"id":"Snhf4JEE3Ox7"},"source":["## 2.6. Function calling\n"]},{"cell_type":"markdown","metadata":{"id":"NhHc9jQA3Ox7"},"source":["### Function calling のサンプルコード\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ubiW75OM3Ox8"},"outputs":[],"source":["import json\n","\n","\n","def get_current_weather(location, unit=\"fahrenheit\"):\n","    if \"tokyo\" in location.lower():\n","        return json.dumps({\"location\": \"Tokyo\", \"temperature\": \"10\", \"unit\": unit})\n","    elif \"san francisco\" in location.lower():\n","        return json.dumps(\n","            {\"location\": \"San Francisco\", \"temperature\": \"72\", \"unit\": unit}\n","        )\n","    elif \"paris\" in location.lower():\n","        return json.dumps({\"location\": \"Paris\", \"temperature\": \"22\", \"unit\": unit})\n","    else:\n","        return json.dumps({\"location\": location, \"temperature\": \"unknown\"})"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H4B9pA2u3Ox8"},"outputs":[],"source":["tools = [\n","    {\n","        \"type\": \"function\",\n","        \"function\": {\n","            \"name\": \"get_current_weather\",\n","            \"description\": \"Get the current weather in a given location\",\n","            \"parameters\": {\n","                \"type\": \"object\",\n","                \"properties\": {\n","                    \"location\": {\n","                        \"type\": \"string\",\n","                        \"description\": \"The city and state, e.g. San Francisco, CA\",\n","                    },\n","                    \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n","                },\n","                \"required\": [\"location\"],\n","            },\n","        },\n","    }\n","]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WKYEFc913Ox8"},"outputs":[],"source":["from openai import OpenAI\n","\n","client = OpenAI()\n","\n","messages = [\n","    {\"role\": \"user\", \"content\": \"東京の天気はどうですか？\"},\n","]\n","\n","response = client.chat.completions.create(\n","    model=\"gpt-4o\",\n","    messages=messages,\n","    tools=tools,\n",")\n","print(response.to_json(indent=2))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JCBPOpIm3Ox8"},"outputs":[],"source":["response_message = response.choices[0].message\n","messages.append(response_message.to_dict())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yAuf66jS3Ox9"},"outputs":[],"source":["available_functions = {\n","    \"get_current_weather\": get_current_weather,\n","}\n","\n","# 使いたい関数は複数あるかもしれないのでループ\n","for tool_call in response_message.tool_calls:\n","    # 関数を実行\n","    function_name = tool_call.function.name\n","    function_to_call = available_functions[function_name]\n","    function_args = json.loads(tool_call.function.arguments)\n","    function_response = function_to_call(\n","        location=function_args.get(\"location\"),\n","        unit=function_args.get(\"unit\"),\n","    )\n","    print(function_response)\n","\n","    # 関数の実行結果を会話履歴としてmessagesに追加\n","    messages.append(\n","        {\n","            \"tool_call_id\": tool_call.id,\n","            \"role\": \"tool\",\n","            \"name\": function_name,\n","            \"content\": function_response,\n","        }\n","    )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XO44rxDK3Ox9"},"outputs":[],"source":["print(json.dumps(messages, ensure_ascii=False, indent=2))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W2KUtHcx3Ox9"},"outputs":[],"source":["second_response = client.chat.completions.create(\n","    model=\"gpt-4o\",\n","    messages=messages,\n",")\n","print(second_response.to_json(indent=2))"]}]}